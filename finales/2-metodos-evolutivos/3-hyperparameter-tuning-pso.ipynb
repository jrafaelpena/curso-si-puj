{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cfe2a19",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5650c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn import Sequential, Linear, ReLU, LeakyReLU, Sigmoid, Dropout\n",
    "from train import _compute_metrics, train_epoch, eval_epoch, train_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from train import train_model\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e4d07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = Path(Path.cwd()).parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5d683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 7777"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e96d6b",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f83d5438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>smoking</th>\n",
       "      <th>finger_discoloration</th>\n",
       "      <th>mental_stress</th>\n",
       "      <th>exposure_to_pollution</th>\n",
       "      <th>long_term_illness</th>\n",
       "      <th>energy_level</th>\n",
       "      <th>immune_weakness</th>\n",
       "      <th>breathing_issue</th>\n",
       "      <th>alcohol_consumption</th>\n",
       "      <th>throat_discomfort</th>\n",
       "      <th>oxygen_saturation</th>\n",
       "      <th>chest_tightness</th>\n",
       "      <th>family_history</th>\n",
       "      <th>smoking_family_history</th>\n",
       "      <th>stress_immune</th>\n",
       "      <th>pulmonary_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57.831178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95.977287</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47.694835</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>97.184483</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.577435</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94.974939</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59.785767</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>95.187900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>59.733941</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93.503008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57.684285</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>94.057151</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52.647022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96.773598</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.306451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>95.019018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64.272789</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98.539379</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.319319</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96.055097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  smoking  finger_discoloration  mental_stress  \\\n",
       "0   68       1        1                     1              1   \n",
       "1   81       1        1                     0              0   \n",
       "2   58       1        1                     0              0   \n",
       "3   44       0        1                     0              1   \n",
       "4   72       0        1                     1              1   \n",
       "5   37       1        1                     1              1   \n",
       "6   50       0        1                     1              1   \n",
       "7   68       0        1                     1              1   \n",
       "8   48       0        1                     1              0   \n",
       "9   52       0        0                     0              1   \n",
       "\n",
       "   exposure_to_pollution  long_term_illness  energy_level  immune_weakness  \\\n",
       "0                      1                  0     57.831178                0   \n",
       "1                      1                  1     47.694835                1   \n",
       "2                      0                  0     59.577435                0   \n",
       "3                      1                  0     59.785767                0   \n",
       "4                      1                  1     59.733941                0   \n",
       "5                      1                  1     57.684285                0   \n",
       "6                      0                  1     52.647022                1   \n",
       "7                      0                  1     53.306451                0   \n",
       "8                      1                  1     64.272789                1   \n",
       "9                      1                  1     58.319319                0   \n",
       "\n",
       "   breathing_issue  alcohol_consumption  throat_discomfort  oxygen_saturation  \\\n",
       "0                0                    1                  1          95.977287   \n",
       "1                1                    0                  1          97.184483   \n",
       "2                1                    1                  0          94.974939   \n",
       "3                1                    0                  1          95.187900   \n",
       "4                1                    0                  1          93.503008   \n",
       "5                1                    1                  1          94.057151   \n",
       "6                1                    1                  0          96.773598   \n",
       "7                0                    0                  1          95.019018   \n",
       "8                1                    0                  1          98.539379   \n",
       "9                1                    0                  1          96.055097   \n",
       "\n",
       "   chest_tightness  family_history  smoking_family_history  stress_immune  \\\n",
       "0                1               0                       0              0   \n",
       "1                0               0                       0              0   \n",
       "2                0               0                       0              0   \n",
       "3                0               0                       0              0   \n",
       "4                0               0                       0              0   \n",
       "5                1               0                       0              0   \n",
       "6                0               0                       0              1   \n",
       "7                0               0                       0              0   \n",
       "8                1               0                       0              0   \n",
       "9                0               0                       0              0   \n",
       "\n",
       "  pulmonary_disease  \n",
       "0                NO  \n",
       "1               YES  \n",
       "2                NO  \n",
       "3               YES  \n",
       "4               YES  \n",
       "5               YES  \n",
       "6                NO  \n",
       "7                NO  \n",
       "8               YES  \n",
       "9                NO  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_detection_path = project_path / \"data/inputs/Lung Cancer Dataset.csv\"\n",
    "df_detection = pd.read_csv(cancer_detection_path)\n",
    "\n",
    "df_detection.columns = [x for x in df_detection.columns.str.lower().str.replace(\" \", \"_\")]\n",
    "\n",
    "df_detection.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e9e5be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 18)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_detection.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce91874",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd042a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label column to numerical values\n",
    "label_map_dict = {\n",
    "    'NO': 0,\n",
    "    'YES': 1\n",
    "}\n",
    "\n",
    "df_detection['pulmonary_disease'] = df_detection['pulmonary_disease'].map(label_map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "499a2506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert binary columns to categorical\n",
    "binary_columns = [\n",
    "    'gender',\n",
    "    'smoking',\n",
    "    'finger_discoloration',\n",
    "    'mental_stress',\n",
    "    'exposure_to_pollution',\n",
    "    'long_term_illness',\n",
    "    'immune_weakness',\n",
    "    'breathing_issue',\n",
    "    'alcohol_consumption',\n",
    "    'throat_discomfort',\n",
    "    'chest_tightness',\n",
    "    'family_history',\n",
    "    'smoking_family_history',\n",
    "    'stress_immune',\n",
    "    'pulmonary_disease'\n",
    "]\n",
    "\n",
    "df_detection[binary_columns] = df_detection[binary_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8672bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_detection.drop(columns=['pulmonary_disease']).values\n",
    "y = df_detection['pulmonary_disease'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=SEED, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=SEED, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83fa335d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (3612, 17)\n",
      "Validation set shape: (638, 17)\n",
      "Test set shape: (750, 17)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2df9f2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([57.37015504,  0.49612403,  0.66196013,  0.60354374,  0.54512735,\n",
       "         0.51522702,  0.43992248, 54.99256295,  0.39451827,  0.79983389,\n",
       "         0.35022148,  0.69988926, 94.9913959 ,  0.6013289 ,  0.303433  ,\n",
       "         0.20265781,  0.21179402]),\n",
       " array([15.83079571,  0.49998498,  0.47304219,  0.48916121,  0.49795936,\n",
       "         0.49976808,  0.49637757,  7.84740972,  0.48874697,  0.40012453,\n",
       "         0.4770392 ,  0.45830589,  1.49321387,  0.48962481,  0.4597406 ,\n",
       "         0.40197963,  0.40857963]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.mean(axis=0), X_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "656fbaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ga_results.pkl\", \"rb\") as f:\n",
    "    ga_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e26891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1]\n",
      "[ True False  True  True False  True False  True  True  True False  True\n",
      " False False  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "best_feature_set = ga_results['best_individual']\n",
    "best_feature_mask = np.array(best_feature_set, dtype=bool)\n",
    "print(best_feature_set)\n",
    "print(best_feature_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d6a6724",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:,best_feature_mask]\n",
    "X_val = X_val[:,best_feature_mask]\n",
    "X_test = X_test[:,best_feature_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d090f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc393390",
   "metadata": {},
   "source": [
    "### GA-FS performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad573d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1285ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "\n",
    "mlp = Sequential(\n",
    "    Linear(11, 64),\n",
    "    ReLU(),\n",
    "    Dropout(0.4),\n",
    "    Linear(64, 32),\n",
    "    ReLU(),\n",
    "    Dropout(0.4),\n",
    "    Linear(32, 16),\n",
    "    ReLU(),\n",
    "    Dropout(0.1),\n",
    "    Linear(16, 2)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005, weight_decay=1e-3)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823415ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 300 epochs with patience=75\n",
      "====================================================================================================\n",
      "Epoch   1/300 | Train: Loss 0.6826 Acc 57.12% F1 0.5923 AUROC 0.6444 | Val: Loss 0.6418 Acc 81.03% F1 0.7218 AUROC 0.8864\n",
      "Epoch  10/300 | Train: Loss 0.3474 Acc 88.21% F1 0.8551 AUROC 0.9197 | Val: Loss 0.2708 Acc 91.69% F1 0.8983 AUROC 0.9445\n",
      "Epoch  20/300 | Train: Loss 0.3252 Acc 89.81% F1 0.8742 AUROC 0.9233 | Val: Loss 0.2568 Acc 92.48% F1 0.9077 AUROC 0.9451\n",
      "Epoch  30/300 | Train: Loss 0.3117 Acc 89.95% F1 0.8759 AUROC 0.9291 | Val: Loss 0.2474 Acc 92.79% F1 0.9112 AUROC 0.9453\n",
      "Epoch  40/300 | Train: Loss 0.3000 Acc 90.31% F1 0.8807 AUROC 0.9321 | Val: Loss 0.2415 Acc 93.10% F1 0.9141 AUROC 0.9472\n",
      "Epoch  50/300 | Train: Loss 0.3016 Acc 90.42% F1 0.8813 AUROC 0.9279 | Val: Loss 0.2381 Acc 93.10% F1 0.9151 AUROC 0.9463\n",
      "Epoch  60/300 | Train: Loss 0.2959 Acc 91.00% F1 0.8892 AUROC 0.9271 | Val: Loss 0.2346 Acc 93.57% F1 0.9204 AUROC 0.9468\n",
      "Epoch  70/300 | Train: Loss 0.2940 Acc 90.70% F1 0.8851 AUROC 0.9285 | Val: Loss 0.2345 Acc 93.57% F1 0.9204 AUROC 0.9466\n",
      "Epoch  80/300 | Train: Loss 0.2914 Acc 90.70% F1 0.8852 AUROC 0.9299 | Val: Loss 0.2298 Acc 93.73% F1 0.9228 AUROC 0.9472\n",
      "Epoch  90/300 | Train: Loss 0.2849 Acc 91.14% F1 0.8906 AUROC 0.9308 | Val: Loss 0.2314 Acc 93.73% F1 0.9225 AUROC 0.9472\n",
      "Epoch 100/300 | Train: Loss 0.2845 Acc 91.14% F1 0.8909 AUROC 0.9328 | Val: Loss 0.2277 Acc 93.73% F1 0.9231 AUROC 0.9469\n",
      "Epoch 110/300 | Train: Loss 0.2892 Acc 91.00% F1 0.8896 AUROC 0.9280 | Val: Loss 0.2287 Acc 93.73% F1 0.9228 AUROC 0.9475\n",
      "Epoch 120/300 | Train: Loss 0.2849 Acc 91.28% F1 0.8924 AUROC 0.9314 | Val: Loss 0.2289 Acc 93.73% F1 0.9228 AUROC 0.9470\n",
      "Epoch 130/300 | Train: Loss 0.2835 Acc 91.22% F1 0.8918 AUROC 0.9313 | Val: Loss 0.2294 Acc 93.57% F1 0.9201 AUROC 0.9481\n",
      "Epoch 140/300 | Train: Loss 0.2808 Acc 91.06% F1 0.8894 AUROC 0.9342 | Val: Loss 0.2271 Acc 93.89% F1 0.9249 AUROC 0.9486\n",
      "Epoch 150/300 | Train: Loss 0.2803 Acc 91.36% F1 0.8934 AUROC 0.9337 | Val: Loss 0.2255 Acc 94.04% F1 0.9264 AUROC 0.9484\n",
      "Epoch 160/300 | Train: Loss 0.2783 Acc 91.25% F1 0.8922 AUROC 0.9358 | Val: Loss 0.2264 Acc 93.57% F1 0.9198 AUROC 0.9480\n",
      "Epoch 170/300 | Train: Loss 0.2751 Acc 91.03% F1 0.8896 AUROC 0.9386 | Val: Loss 0.2260 Acc 93.89% F1 0.9246 AUROC 0.9484\n",
      "Epoch 180/300 | Train: Loss 0.2783 Acc 91.31% F1 0.8925 AUROC 0.9362 | Val: Loss 0.2244 Acc 93.57% F1 0.9201 AUROC 0.9486\n",
      "Epoch 190/300 | Train: Loss 0.2785 Acc 91.39% F1 0.8939 AUROC 0.9338 | Val: Loss 0.2252 Acc 93.57% F1 0.9201 AUROC 0.9490\n",
      "Epoch 200/300 | Train: Loss 0.2823 Acc 90.92% F1 0.8877 AUROC 0.9349 | Val: Loss 0.2241 Acc 93.89% F1 0.9249 AUROC 0.9481\n",
      "Epoch 210/300 | Train: Loss 0.2777 Acc 91.25% F1 0.8916 AUROC 0.9342 | Val: Loss 0.2245 Acc 93.73% F1 0.9225 AUROC 0.9485\n",
      "Epoch 220/300 | Train: Loss 0.2783 Acc 91.28% F1 0.8922 AUROC 0.9351 | Val: Loss 0.2237 Acc 93.73% F1 0.9225 AUROC 0.9484\n",
      "Epoch 230/300 | Train: Loss 0.2772 Acc 91.33% F1 0.8930 AUROC 0.9366 | Val: Loss 0.2245 Acc 93.42% F1 0.9180 AUROC 0.9476\n",
      "Epoch 240/300 | Train: Loss 0.2754 Acc 91.28% F1 0.8922 AUROC 0.9380 | Val: Loss 0.2255 Acc 93.42% F1 0.9180 AUROC 0.9482\n",
      "Epoch 250/300 | Train: Loss 0.2752 Acc 91.31% F1 0.8926 AUROC 0.9364 | Val: Loss 0.2272 Acc 93.57% F1 0.9207 AUROC 0.9479\n",
      "Epoch 260/300 | Train: Loss 0.2771 Acc 91.00% F1 0.8890 AUROC 0.9365 | Val: Loss 0.2263 Acc 93.57% F1 0.9201 AUROC 0.9494\n",
      "Epoch 270/300 | Train: Loss 0.2799 Acc 91.09% F1 0.8899 AUROC 0.9349 | Val: Loss 0.2248 Acc 93.42% F1 0.9176 AUROC 0.9502\n",
      "Epoch 280/300 | Train: Loss 0.2751 Acc 91.42% F1 0.8945 AUROC 0.9374 | Val: Loss 0.2276 Acc 93.42% F1 0.9180 AUROC 0.9504\n",
      "Epoch 290/300 | Train: Loss 0.2773 Acc 91.33% F1 0.8934 AUROC 0.9370 | Val: Loss 0.2260 Acc 93.57% F1 0.9198 AUROC 0.9496\n",
      "Epoch 300/300 | Train: Loss 0.2758 Acc 91.14% F1 0.8908 AUROC 0.9388 | Val: Loss 0.2275 Acc 93.26% F1 0.9155 AUROC 0.9495\n",
      "====================================================================================================\n",
      "Training completed. Best model from epoch 226\n",
      "Best validation loss: 0.2219\n"
     ]
    }
   ],
   "source": [
    "results = train_model(mlp, train_loader, val_loader, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a84ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': {'train_loss': [0.6826017606562026,\n",
       "   0.5845653975788805,\n",
       "   0.43680377916772234,\n",
       "   0.38684230247473267,\n",
       "   0.37923739137641616,\n",
       "   0.37093565887787017,\n",
       "   0.3531559946331075,\n",
       "   0.35767152423610454,\n",
       "   0.34649571172422744,\n",
       "   0.3474013962156881,\n",
       "   0.3417155562445175,\n",
       "   0.3404845670608191,\n",
       "   0.34186668814482746,\n",
       "   0.34758039493761456,\n",
       "   0.33622041202726816,\n",
       "   0.3282901802464313,\n",
       "   0.33028922600471566,\n",
       "   0.3237342142385502,\n",
       "   0.325867342674983,\n",
       "   0.325176298684324,\n",
       "   0.3262396673295453,\n",
       "   0.32826001834895785,\n",
       "   0.31625809862896187,\n",
       "   0.3206654550427218,\n",
       "   0.3171541178774332,\n",
       "   0.3099159032502444,\n",
       "   0.31297693517913056,\n",
       "   0.3114269238505781,\n",
       "   0.31101381501486136,\n",
       "   0.3116893006255592,\n",
       "   0.3120533089470098,\n",
       "   0.3112445581592991,\n",
       "   0.30589934716523026,\n",
       "   0.30903150015825187,\n",
       "   0.3121651195542493,\n",
       "   0.30856863730241557,\n",
       "   0.31095457813008415,\n",
       "   0.3095104293041715,\n",
       "   0.30186246125933075,\n",
       "   0.30002068364342976,\n",
       "   0.3070234376462723,\n",
       "   0.30670279386563687,\n",
       "   0.3003917133821337,\n",
       "   0.3039078946789502,\n",
       "   0.29939096997742637,\n",
       "   0.30191040854253376,\n",
       "   0.3005854817785958,\n",
       "   0.2937411854697488,\n",
       "   0.29748626919679866,\n",
       "   0.30160102944569467,\n",
       "   0.2995955442735391,\n",
       "   0.2950422147810789,\n",
       "   0.292058135715962,\n",
       "   0.29841364070294574,\n",
       "   0.2973982579882359,\n",
       "   0.29482074350877724,\n",
       "   0.29595935499813336,\n",
       "   0.29605678473068103,\n",
       "   0.2937323996758012,\n",
       "   0.2959142938206758,\n",
       "   0.2960877005807057,\n",
       "   0.2977693261267207,\n",
       "   0.29475753522526515,\n",
       "   0.2897103521580976,\n",
       "   0.2900623659688901,\n",
       "   0.2874146945782806,\n",
       "   0.29329936100729015,\n",
       "   0.2905101170835569,\n",
       "   0.2958508171842476,\n",
       "   0.29397386117763036,\n",
       "   0.28795782815776394,\n",
       "   0.29079837550884596,\n",
       "   0.28608828287980087,\n",
       "   0.28825628744275333,\n",
       "   0.2896949768660472,\n",
       "   0.28822039112300174,\n",
       "   0.2873317192691241,\n",
       "   0.2910839988048686,\n",
       "   0.2814288903378437,\n",
       "   0.29138003948122954,\n",
       "   0.2871716098069881,\n",
       "   0.2880888897368678,\n",
       "   0.2896785573540864,\n",
       "   0.28674156975376514,\n",
       "   0.2873177635973342,\n",
       "   0.2900728847365311,\n",
       "   0.2908874299637107,\n",
       "   0.28448389797313667,\n",
       "   0.29207536848808574,\n",
       "   0.2848982444303244,\n",
       "   0.29257565667462904,\n",
       "   0.2885447414478458,\n",
       "   0.2837906886110802,\n",
       "   0.2918975835754758,\n",
       "   0.2859892449439694,\n",
       "   0.2848227457416678,\n",
       "   0.28758255625814033,\n",
       "   0.28364755975645645,\n",
       "   0.28400145152610534,\n",
       "   0.28454631426735705,\n",
       "   0.28456426125560225,\n",
       "   0.28484634921400254,\n",
       "   0.28343579437117505,\n",
       "   0.2871214669292683,\n",
       "   0.28101235192479485,\n",
       "   0.28426613542328644,\n",
       "   0.2828035952970963,\n",
       "   0.28315192507218945,\n",
       "   0.2844428285741859,\n",
       "   0.28922609115227776,\n",
       "   0.2819287088572781,\n",
       "   0.2864782191392195,\n",
       "   0.2809014544303499,\n",
       "   0.2824379154217996,\n",
       "   0.28333452173146695,\n",
       "   0.28628557164671675,\n",
       "   0.2767321071850501,\n",
       "   0.2835288414131367,\n",
       "   0.28465700482873296,\n",
       "   0.2848693498411316,\n",
       "   0.2849357270719205,\n",
       "   0.2804938831499645,\n",
       "   0.2844791605095003,\n",
       "   0.2792654541771805,\n",
       "   0.2826192993856348,\n",
       "   0.2865775986466297,\n",
       "   0.2810749725447937,\n",
       "   0.2825238388506149,\n",
       "   0.282171070278681,\n",
       "   0.2835003529672211,\n",
       "   0.28274822880329353,\n",
       "   0.27682780047851807,\n",
       "   0.2790382937801505,\n",
       "   0.28510481294075385,\n",
       "   0.2824080363328539,\n",
       "   0.28404972313646465,\n",
       "   0.2778908583610953,\n",
       "   0.2790328713416525,\n",
       "   0.28521571246492505,\n",
       "   0.2807841174560264,\n",
       "   0.27965599849638617,\n",
       "   0.28072593315759237,\n",
       "   0.28106790467486165,\n",
       "   0.28282906011093495,\n",
       "   0.278793153902753,\n",
       "   0.28263432371655967,\n",
       "   0.2819178444751077,\n",
       "   0.2815400363004881,\n",
       "   0.2796590755944236,\n",
       "   0.2803030650184004,\n",
       "   0.276968231067837,\n",
       "   0.2825987715591756,\n",
       "   0.28139235434078036,\n",
       "   0.28289333677305073,\n",
       "   0.2791960002113946,\n",
       "   0.28112870354126984,\n",
       "   0.2806982658762208,\n",
       "   0.2827723071160639,\n",
       "   0.280175620782811,\n",
       "   0.27834976861379207,\n",
       "   0.2845091045166831,\n",
       "   0.28010255667656364,\n",
       "   0.28093076715965737,\n",
       "   0.2729266158337081,\n",
       "   0.27622521154640256,\n",
       "   0.28285430360210034,\n",
       "   0.27903230592261913,\n",
       "   0.27974859556618453,\n",
       "   0.2815146373289896,\n",
       "   0.27506830430242046,\n",
       "   0.27974374155005477,\n",
       "   0.27815099286610634,\n",
       "   0.2817912102075642,\n",
       "   0.28151619678583917,\n",
       "   0.2785857076594732,\n",
       "   0.28286516578952603,\n",
       "   0.2755118000546959,\n",
       "   0.27771870536133564,\n",
       "   0.27781631717518185,\n",
       "   0.27825336329894734,\n",
       "   0.28088723728691095,\n",
       "   0.2792918187703273,\n",
       "   0.278735959434166,\n",
       "   0.2782094930510056,\n",
       "   0.2767560352320687,\n",
       "   0.2789397667742779,\n",
       "   0.2779571720267979,\n",
       "   0.27900242221315835,\n",
       "   0.2800225846692177,\n",
       "   0.2785140585859749,\n",
       "   0.2740228912429028,\n",
       "   0.27828328550720005,\n",
       "   0.28072565163620816,\n",
       "   0.2800420898931763,\n",
       "   0.2802040444837588,\n",
       "   0.2801701508355167,\n",
       "   0.27479178188647146,\n",
       "   0.2775726010105011,\n",
       "   0.2761425909937946,\n",
       "   0.2822534509275443,\n",
       "   0.28042759047460186,\n",
       "   0.2769432328930197,\n",
       "   0.2773102259187075,\n",
       "   0.2785030322217466,\n",
       "   0.2782224300394819,\n",
       "   0.2744765554865201,\n",
       "   0.2731795571208132,\n",
       "   0.28175931292712886,\n",
       "   0.2745576395940939,\n",
       "   0.2776620496283074,\n",
       "   0.2814565170081879,\n",
       "   0.28173465724799324,\n",
       "   0.275806206702394,\n",
       "   0.27465374932798703,\n",
       "   0.27795622293999295,\n",
       "   0.27828511113872295,\n",
       "   0.28102850514656946,\n",
       "   0.2794887942663195,\n",
       "   0.2770341533099034,\n",
       "   0.278258114937664,\n",
       "   0.2757739866624771,\n",
       "   0.2783248171721846,\n",
       "   0.27520301007353193,\n",
       "   0.2776051058721701,\n",
       "   0.2750138188913415,\n",
       "   0.27890636239733013,\n",
       "   0.2792784841287704,\n",
       "   0.27986347292480807,\n",
       "   0.2784947875396226,\n",
       "   0.27718448406240076,\n",
       "   0.27305484524332935,\n",
       "   0.2797378219111285,\n",
       "   0.27553548986465565,\n",
       "   0.2766799031945558,\n",
       "   0.2777734345045861,\n",
       "   0.2725770541137767,\n",
       "   0.2780785232881375,\n",
       "   0.27443792155282704,\n",
       "   0.2757034819915577,\n",
       "   0.2754217231953527,\n",
       "   0.27666661595453323,\n",
       "   0.2822231113382616,\n",
       "   0.2784893097539545,\n",
       "   0.27641194680930503,\n",
       "   0.27389265433498394,\n",
       "   0.27926083178087197,\n",
       "   0.2774250478063971,\n",
       "   0.27678300970020486,\n",
       "   0.27513537853791203,\n",
       "   0.2751941929755945,\n",
       "   0.2772831247411957,\n",
       "   0.27614686916172837,\n",
       "   0.28000108830028464,\n",
       "   0.274330718226211,\n",
       "   0.2757073862608089,\n",
       "   0.27864500739150666,\n",
       "   0.27381436881564913,\n",
       "   0.27506257971523873,\n",
       "   0.27700380144325204,\n",
       "   0.2771163984621614,\n",
       "   0.2734604115501987,\n",
       "   0.276524455576376,\n",
       "   0.27480886056441667,\n",
       "   0.2748017415717855,\n",
       "   0.2755063096616223,\n",
       "   0.27585107038583473,\n",
       "   0.2762595143825113,\n",
       "   0.27630624678377824,\n",
       "   0.2759581277866828,\n",
       "   0.2799049561733951,\n",
       "   0.2739166075968135,\n",
       "   0.27328463666066777,\n",
       "   0.2774955457858205,\n",
       "   0.27258913971458953,\n",
       "   0.27687183441645813,\n",
       "   0.2802430510454928,\n",
       "   0.27378710648942234,\n",
       "   0.27876711236612084,\n",
       "   0.2772794413738208,\n",
       "   0.27507049797447286,\n",
       "   0.274581065523136,\n",
       "   0.27604667236770636,\n",
       "   0.277847932620698,\n",
       "   0.2705957185918443,\n",
       "   0.2699300953716139,\n",
       "   0.27382825145029677,\n",
       "   0.27424363478407643,\n",
       "   0.27008001715901947,\n",
       "   0.2724736107478242,\n",
       "   0.27726061447448247,\n",
       "   0.27656537631025346,\n",
       "   0.27580559451714703,\n",
       "   0.26991661883073786,\n",
       "   0.2731850102857366,\n",
       "   0.27557658579856453,\n",
       "   0.2793309606058917,\n",
       "   0.2750994361450242,\n",
       "   0.2781973199986936,\n",
       "   0.27174039642148107,\n",
       "   0.2758164484041474],\n",
       "  'val_loss': [0.6418339497990743,\n",
       "   0.4592205596194372,\n",
       "   0.322494880999891,\n",
       "   0.2984042452140288,\n",
       "   0.2899752668452487,\n",
       "   0.2850562907685307,\n",
       "   0.2805013751908903,\n",
       "   0.27734690586975,\n",
       "   0.27433831980422746,\n",
       "   0.27082392353809737,\n",
       "   0.27031073852392573,\n",
       "   0.26882950643947506,\n",
       "   0.2680759029608909,\n",
       "   0.26566133468315517,\n",
       "   0.2622649431882607,\n",
       "   0.26136872560066116,\n",
       "   0.26154022297141694,\n",
       "   0.25941139604417507,\n",
       "   0.2588400938854696,\n",
       "   0.25681136427067663,\n",
       "   0.2558419152300186,\n",
       "   0.25710598152819847,\n",
       "   0.25320065199020886,\n",
       "   0.2515217766959839,\n",
       "   0.25205412105333097,\n",
       "   0.2509854736279544,\n",
       "   0.2503252198049641,\n",
       "   0.2500948772815328,\n",
       "   0.24782574667265422,\n",
       "   0.24741901569418773,\n",
       "   0.24917636101709265,\n",
       "   0.24638665362398451,\n",
       "   0.24542025422975186,\n",
       "   0.24539191665881105,\n",
       "   0.24757728830774003,\n",
       "   0.24483505512666554,\n",
       "   0.2433245012472416,\n",
       "   0.24283028919495012,\n",
       "   0.24284717094935593,\n",
       "   0.2415173534876127,\n",
       "   0.24235612270787218,\n",
       "   0.2421308114050324,\n",
       "   0.23972221078543826,\n",
       "   0.23874292184006085,\n",
       "   0.23981776898931187,\n",
       "   0.2410852499422982,\n",
       "   0.24055025500003074,\n",
       "   0.23783588287972357,\n",
       "   0.23923418397626905,\n",
       "   0.23814498784960625,\n",
       "   0.23809455078223657,\n",
       "   0.23814322899875223,\n",
       "   0.2362907569049668,\n",
       "   0.23714726415921156,\n",
       "   0.2339164590387135,\n",
       "   0.23556863579630477,\n",
       "   0.23487928276151698,\n",
       "   0.23498340693760816,\n",
       "   0.2371241881929595,\n",
       "   0.23456566007720267,\n",
       "   0.23638463160461018,\n",
       "   0.23465013223755696,\n",
       "   0.23379250478034483,\n",
       "   0.23292286142847007,\n",
       "   0.23443413191828236,\n",
       "   0.23330369974752205,\n",
       "   0.23268328303453692,\n",
       "   0.23383672096325686,\n",
       "   0.2363867842852135,\n",
       "   0.23451180359039187,\n",
       "   0.23202750922931026,\n",
       "   0.22971860106835917,\n",
       "   0.2315524049967434,\n",
       "   0.23085530971098095,\n",
       "   0.23167048773048066,\n",
       "   0.23064166919377904,\n",
       "   0.2300510941814853,\n",
       "   0.23111715725970491,\n",
       "   0.2308455945742915,\n",
       "   0.22976470871778865,\n",
       "   0.22943751504615556,\n",
       "   0.22986282235402672,\n",
       "   0.23134010450967052,\n",
       "   0.2293477236850882,\n",
       "   0.23006898281529406,\n",
       "   0.2317879239219857,\n",
       "   0.22863999448226163,\n",
       "   0.230676778244748,\n",
       "   0.23148028398382253,\n",
       "   0.2314237437464974,\n",
       "   0.23059367124563473,\n",
       "   0.23177706331108058,\n",
       "   0.22887693140013465,\n",
       "   0.22939905089831278,\n",
       "   0.23002968275434918,\n",
       "   0.22872654070674814,\n",
       "   0.23060540588671885,\n",
       "   0.22925311275597277,\n",
       "   0.22713331962267058,\n",
       "   0.22765440645636437,\n",
       "   0.22882192117106578,\n",
       "   0.22847465320627516,\n",
       "   0.22833998510643233,\n",
       "   0.2291688909724962,\n",
       "   0.2282358854541958,\n",
       "   0.2281346518698157,\n",
       "   0.22882556849886257,\n",
       "   0.23009882498310652,\n",
       "   0.22672412383332147,\n",
       "   0.2286793925452008,\n",
       "   0.22888671282129974,\n",
       "   0.22951703707813095,\n",
       "   0.22963555428114804,\n",
       "   0.2285244873605178,\n",
       "   0.22940052527245308,\n",
       "   0.22796475424848753,\n",
       "   0.22791182013888345,\n",
       "   0.22820637863257837,\n",
       "   0.23207501417790835,\n",
       "   0.22886595372869678,\n",
       "   0.22894615953245134,\n",
       "   0.22996883608143906,\n",
       "   0.2281077515836046,\n",
       "   0.22659070981333623,\n",
       "   0.22827286495123536,\n",
       "   0.22741558465838058,\n",
       "   0.22922163785998725,\n",
       "   0.22739806023884718,\n",
       "   0.22917109139286987,\n",
       "   0.22935189255352678,\n",
       "   0.22641400834049177,\n",
       "   0.22583299160564207,\n",
       "   0.22679805942463652,\n",
       "   0.22782849910490938,\n",
       "   0.2263667409696549,\n",
       "   0.2265908766689719,\n",
       "   0.22566091659300752,\n",
       "   0.22507802614223996,\n",
       "   0.22870496499314202,\n",
       "   0.22711159718634566,\n",
       "   0.22662666682913013,\n",
       "   0.22647349069297873,\n",
       "   0.2271893034254122,\n",
       "   0.2287765975843029,\n",
       "   0.2265197606669698,\n",
       "   0.22637314393789418,\n",
       "   0.22747975559817588,\n",
       "   0.22645866730743816,\n",
       "   0.22743246687990745,\n",
       "   0.22552042382077364,\n",
       "   0.22731955699786124,\n",
       "   0.22885085917939213,\n",
       "   0.22659492791633248,\n",
       "   0.22783947551512046,\n",
       "   0.2256420514893756,\n",
       "   0.22897051709199026,\n",
       "   0.22611837897181136,\n",
       "   0.22596943677405953,\n",
       "   0.22944484188638883,\n",
       "   0.2264021740157776,\n",
       "   0.22964486769374262,\n",
       "   0.2291549876752692,\n",
       "   0.22616977195567844,\n",
       "   0.2253739258805786,\n",
       "   0.22693842149640325,\n",
       "   0.22761085405245096,\n",
       "   0.22630664141013704,\n",
       "   0.22726185320873618,\n",
       "   0.22818770855198087,\n",
       "   0.226023646871498,\n",
       "   0.2278784782068109,\n",
       "   0.22631480444374502,\n",
       "   0.2267258263960901,\n",
       "   0.22686542972315069,\n",
       "   0.22744889113596614,\n",
       "   0.22590748190319276,\n",
       "   0.2259778703174621,\n",
       "   0.22640678113717644,\n",
       "   0.2276685717150709,\n",
       "   0.22440407025776687,\n",
       "   0.2277984202001536,\n",
       "   0.22488825224036332,\n",
       "   0.22399991512485432,\n",
       "   0.22350029493200368,\n",
       "   0.22393988722170408,\n",
       "   0.22604955083524172,\n",
       "   0.22515987513767888,\n",
       "   0.22481901798876103,\n",
       "   0.22560823458862903,\n",
       "   0.22519604109671423,\n",
       "   0.22532241055771102,\n",
       "   0.22709088387160464,\n",
       "   0.22754645342924004,\n",
       "   0.22418008174828974,\n",
       "   0.2254199541194312,\n",
       "   0.22561292826755666,\n",
       "   0.22360732745040546,\n",
       "   0.22669448827314526,\n",
       "   0.22486949840496326,\n",
       "   0.22405046191895645,\n",
       "   0.2235527823337567,\n",
       "   0.22550969152801836,\n",
       "   0.22487373836922422,\n",
       "   0.22595525731487334,\n",
       "   0.2264141573521037,\n",
       "   0.22752821394081774,\n",
       "   0.2226822333276085,\n",
       "   0.22586619246716036,\n",
       "   0.22398874322448778,\n",
       "   0.22445685927957576,\n",
       "   0.22685067729329614,\n",
       "   0.22612556646983825,\n",
       "   0.22610180911412434,\n",
       "   0.2242189590179808,\n",
       "   0.22507278733305797,\n",
       "   0.22394345364413665,\n",
       "   0.22473962544273807,\n",
       "   0.22686112903315445,\n",
       "   0.22372836449116376,\n",
       "   0.2237380163329522,\n",
       "   0.22383752161619433,\n",
       "   0.22545834063175704,\n",
       "   0.2235136203070793,\n",
       "   0.22476540674049653,\n",
       "   0.2232095120842554,\n",
       "   0.22194582630287518,\n",
       "   0.22461265680558257,\n",
       "   0.2242221812189186,\n",
       "   0.2234666484837248,\n",
       "   0.22445230260724933,\n",
       "   0.2236077343595439,\n",
       "   0.22459158287339823,\n",
       "   0.2257393432261428,\n",
       "   0.22390786159001175,\n",
       "   0.2244108413173861,\n",
       "   0.22407899526032535,\n",
       "   0.22515867603796777,\n",
       "   0.2247087785909916,\n",
       "   0.22618479951982587,\n",
       "   0.22547499928915388,\n",
       "   0.22511303308054945,\n",
       "   0.2274766245792652,\n",
       "   0.22427402768389185,\n",
       "   0.22843750036061744,\n",
       "   0.22717425684943843,\n",
       "   0.22473813527990658,\n",
       "   0.2260310970783981,\n",
       "   0.22576314771436973,\n",
       "   0.2278282609666029,\n",
       "   0.22715674667709673,\n",
       "   0.22528381916609677,\n",
       "   0.22654742133281075,\n",
       "   0.22738282522624562,\n",
       "   0.2265420032892855,\n",
       "   0.2254561727697199,\n",
       "   0.22494296136320946,\n",
       "   0.22403257482664712,\n",
       "   0.2240867492827502,\n",
       "   0.22766707870280106,\n",
       "   0.22633995909862759,\n",
       "   0.2247629430507044,\n",
       "   0.22653951586974452,\n",
       "   0.2254465148553579,\n",
       "   0.226051092988645,\n",
       "   0.22503360965782573,\n",
       "   0.22597830403934827,\n",
       "   0.22437014778766512,\n",
       "   0.2265383270934084,\n",
       "   0.22494771324541876,\n",
       "   0.22476683538348696,\n",
       "   0.22378871419399884,\n",
       "   0.2277376063658526,\n",
       "   0.22906473970338467,\n",
       "   0.2251295118963457,\n",
       "   0.2248845205037945,\n",
       "   0.22351121234482732,\n",
       "   0.22532194694007826,\n",
       "   0.22517219662292623,\n",
       "   0.22531409220635704,\n",
       "   0.22760789320573538,\n",
       "   0.22714554432043835,\n",
       "   0.22453930675049186,\n",
       "   0.22503449106851714,\n",
       "   0.22463774223312688,\n",
       "   0.22422703311174266,\n",
       "   0.22655305051504632,\n",
       "   0.22405264925994095,\n",
       "   0.22582088462237654,\n",
       "   0.22442957245070358,\n",
       "   0.2260116308366991,\n",
       "   0.22547705686391334,\n",
       "   0.22614299307422578,\n",
       "   0.22571282102770193,\n",
       "   0.22635568271983753,\n",
       "   0.22567410047711997,\n",
       "   0.22744767671468488,\n",
       "   0.22609390435173968,\n",
       "   0.22639501076133273,\n",
       "   0.22361552864780246,\n",
       "   0.2274822684524575],\n",
       "  'train_acc': [57.11517165005537,\n",
       "   75.47065337763013,\n",
       "   83.02879291251384,\n",
       "   86.48947951273533,\n",
       "   86.57253599114064,\n",
       "   88.06755260243632,\n",
       "   87.92912513842747,\n",
       "   88.03986710963456,\n",
       "   88.84274640088593,\n",
       "   88.20598006644518,\n",
       "   88.89811738648947,\n",
       "   88.81506090808416,\n",
       "   89.11960132890366,\n",
       "   88.92580287929125,\n",
       "   89.28571428571429,\n",
       "   89.20265780730897,\n",
       "   89.34108527131782,\n",
       "   89.59025470653377,\n",
       "   89.6733111849391,\n",
       "   89.81173864894795,\n",
       "   89.7563676633444,\n",
       "   89.78405315614619,\n",
       "   89.8671096345515,\n",
       "   89.562569213732,\n",
       "   89.4795127353267,\n",
       "   90.08859357696566,\n",
       "   89.72868217054264,\n",
       "   90.11627906976744,\n",
       "   90.33776301218161,\n",
       "   89.95016611295681,\n",
       "   90.08859357696566,\n",
       "   90.11627906976744,\n",
       "   90.50387596899225,\n",
       "   90.61461794019934,\n",
       "   90.11627906976744,\n",
       "   90.4485049833887,\n",
       "   90.2547065337763,\n",
       "   90.03322259136213,\n",
       "   90.7530454042082,\n",
       "   90.31007751937985,\n",
       "   90.66998892580288,\n",
       "   90.80841638981174,\n",
       "   90.6423034330011,\n",
       "   90.80841638981174,\n",
       "   90.55924695459579,\n",
       "   90.86378737541528,\n",
       "   90.2547065337763,\n",
       "   90.61461794019934,\n",
       "   90.7530454042082,\n",
       "   90.42081949058694,\n",
       "   90.53156146179403,\n",
       "   90.7530454042082,\n",
       "   90.69767441860465,\n",
       "   90.55924695459579,\n",
       "   90.7530454042082,\n",
       "   90.86378737541528,\n",
       "   90.69767441860465,\n",
       "   90.97452934662238,\n",
       "   90.55924695459579,\n",
       "   91.00221483942414,\n",
       "   90.58693244739756,\n",
       "   90.72535991140643,\n",
       "   90.72535991140643,\n",
       "   90.9468438538206,\n",
       "   91.19601328903654,\n",
       "   91.08527131782945,\n",
       "   90.66998892580288,\n",
       "   91.00221483942414,\n",
       "   90.6423034330011,\n",
       "   90.69767441860465,\n",
       "   91.0299003322259,\n",
       "   90.80841638981174,\n",
       "   91.11295681063123,\n",
       "   90.80841638981174,\n",
       "   91.00221483942414,\n",
       "   91.16832779623478,\n",
       "   90.89147286821705,\n",
       "   91.0299003322259,\n",
       "   91.0299003322259,\n",
       "   90.69767441860465,\n",
       "   91.05758582502769,\n",
       "   91.08527131782945,\n",
       "   91.140642303433,\n",
       "   90.8361018826135,\n",
       "   91.22369878183832,\n",
       "   90.55924695459579,\n",
       "   90.80841638981174,\n",
       "   91.16832779623478,\n",
       "   90.91915836101883,\n",
       "   91.140642303433,\n",
       "   90.91915836101883,\n",
       "   90.86378737541528,\n",
       "   91.22369878183832,\n",
       "   90.69767441860465,\n",
       "   91.36212624584718,\n",
       "   91.05758582502769,\n",
       "   91.140642303433,\n",
       "   91.41749723145072,\n",
       "   91.05758582502769,\n",
       "   91.140642303433,\n",
       "   91.08527131782945,\n",
       "   91.11295681063123,\n",
       "   91.08527131782945,\n",
       "   91.05758582502769,\n",
       "   91.3344407530454,\n",
       "   90.78073089700996,\n",
       "   91.19601328903654,\n",
       "   90.91915836101883,\n",
       "   90.8361018826135,\n",
       "   91.00221483942414,\n",
       "   91.19601328903654,\n",
       "   91.11295681063123,\n",
       "   91.36212624584718,\n",
       "   91.0299003322259,\n",
       "   91.11295681063123,\n",
       "   90.9468438538206,\n",
       "   91.0299003322259,\n",
       "   91.16832779623478,\n",
       "   91.19601328903654,\n",
       "   91.27906976744185,\n",
       "   91.140642303433,\n",
       "   91.41749723145072,\n",
       "   90.86378737541528,\n",
       "   91.22369878183832,\n",
       "   91.27906976744185,\n",
       "   90.86378737541528,\n",
       "   91.00221483942414,\n",
       "   91.5282392026578,\n",
       "   91.22369878183832,\n",
       "   91.22369878183832,\n",
       "   91.08527131782945,\n",
       "   91.44518272425249,\n",
       "   91.3344407530454,\n",
       "   90.80841638981174,\n",
       "   91.22369878183832,\n",
       "   91.36212624584718,\n",
       "   91.55592469545958,\n",
       "   91.41749723145072,\n",
       "   91.19601328903654,\n",
       "   91.05758582502769,\n",
       "   91.38981173864894,\n",
       "   91.16832779623478,\n",
       "   91.19601328903654,\n",
       "   91.41749723145072,\n",
       "   91.05758582502769,\n",
       "   91.0299003322259,\n",
       "   91.16832779623478,\n",
       "   91.05758582502769,\n",
       "   91.19601328903654,\n",
       "   91.36212624584718,\n",
       "   91.25138427464009,\n",
       "   91.11295681063123,\n",
       "   91.27906976744185,\n",
       "   91.08527131782945,\n",
       "   91.47286821705427,\n",
       "   91.61129568106313,\n",
       "   91.58361018826135,\n",
       "   90.9468438538206,\n",
       "   91.11295681063123,\n",
       "   91.25138427464009,\n",
       "   91.08527131782945,\n",
       "   91.38981173864894,\n",
       "   91.3344407530454,\n",
       "   91.55592469545958,\n",
       "   91.16832779623478,\n",
       "   91.08527131782945,\n",
       "   91.30675526024363,\n",
       "   91.25138427464009,\n",
       "   91.08527131782945,\n",
       "   91.0299003322259,\n",
       "   91.25138427464009,\n",
       "   91.16832779623478,\n",
       "   91.0299003322259,\n",
       "   91.05758582502769,\n",
       "   91.44518272425249,\n",
       "   91.05758582502769,\n",
       "   91.25138427464009,\n",
       "   91.22369878183832,\n",
       "   91.47286821705427,\n",
       "   91.30675526024363,\n",
       "   91.140642303433,\n",
       "   91.38981173864894,\n",
       "   91.30675526024363,\n",
       "   91.47286821705427,\n",
       "   90.9468438538206,\n",
       "   91.3344407530454,\n",
       "   91.38981173864894,\n",
       "   91.3344407530454,\n",
       "   91.05758582502769,\n",
       "   91.38981173864894,\n",
       "   91.41749723145072,\n",
       "   91.11295681063123,\n",
       "   91.30675526024363,\n",
       "   90.80841638981174,\n",
       "   91.30675526024363,\n",
       "   91.0299003322259,\n",
       "   91.3344407530454,\n",
       "   91.27906976744185,\n",
       "   91.30675526024363,\n",
       "   90.91915836101883,\n",
       "   91.05758582502769,\n",
       "   91.41749723145072,\n",
       "   91.58361018826135,\n",
       "   91.27906976744185,\n",
       "   91.140642303433,\n",
       "   91.25138427464009,\n",
       "   91.44518272425249,\n",
       "   91.00221483942414,\n",
       "   91.19601328903654,\n",
       "   91.25138427464009,\n",
       "   91.0299003322259,\n",
       "   90.91915836101883,\n",
       "   91.22369878183832,\n",
       "   91.3344407530454,\n",
       "   91.08527131782945,\n",
       "   91.47286821705427,\n",
       "   91.05758582502769,\n",
       "   91.16832779623478,\n",
       "   91.08527131782945,\n",
       "   91.27906976744185,\n",
       "   91.19601328903654,\n",
       "   91.22369878183832,\n",
       "   91.11295681063123,\n",
       "   91.19601328903654,\n",
       "   91.36212624584718,\n",
       "   91.30675526024363,\n",
       "   91.27906976744185,\n",
       "   91.00221483942414,\n",
       "   91.00221483942414,\n",
       "   91.3344407530454,\n",
       "   91.5282392026578,\n",
       "   91.27906976744185,\n",
       "   91.47286821705427,\n",
       "   91.00221483942414,\n",
       "   91.08527131782945,\n",
       "   91.74972314507198,\n",
       "   91.25138427464009,\n",
       "   91.3344407530454,\n",
       "   91.44518272425249,\n",
       "   91.27906976744185,\n",
       "   91.36212624584718,\n",
       "   91.38981173864894,\n",
       "   91.16832779623478,\n",
       "   91.41749723145072,\n",
       "   91.44518272425249,\n",
       "   91.05758582502769,\n",
       "   91.3344407530454,\n",
       "   91.50055370985604,\n",
       "   91.41749723145072,\n",
       "   91.30675526024363,\n",
       "   91.08527131782945,\n",
       "   91.22369878183832,\n",
       "   91.30675526024363,\n",
       "   91.5282392026578,\n",
       "   91.41749723145072,\n",
       "   91.0299003322259,\n",
       "   91.140642303433,\n",
       "   91.25138427464009,\n",
       "   91.3344407530454,\n",
       "   91.00221483942414,\n",
       "   91.30675526024363,\n",
       "   91.16832779623478,\n",
       "   91.19601328903654,\n",
       "   91.3344407530454,\n",
       "   91.5282392026578,\n",
       "   91.5282392026578,\n",
       "   91.0299003322259,\n",
       "   91.27906976744185,\n",
       "   91.140642303433,\n",
       "   91.08527131782945,\n",
       "   91.36212624584718,\n",
       "   91.25138427464009,\n",
       "   91.44518272425249,\n",
       "   91.50055370985604,\n",
       "   91.25138427464009,\n",
       "   91.08527131782945,\n",
       "   91.41749723145072,\n",
       "   91.30675526024363,\n",
       "   91.27906976744185,\n",
       "   91.41749723145072,\n",
       "   91.44518272425249,\n",
       "   91.19601328903654,\n",
       "   91.19601328903654,\n",
       "   91.55592469545958,\n",
       "   91.63898117386489,\n",
       "   91.30675526024363,\n",
       "   91.25138427464009,\n",
       "   91.25138427464009,\n",
       "   91.36212624584718,\n",
       "   91.3344407530454,\n",
       "   91.19601328903654,\n",
       "   91.30675526024363,\n",
       "   91.63898117386489,\n",
       "   91.11295681063123,\n",
       "   91.22369878183832,\n",
       "   91.140642303433,\n",
       "   91.22369878183832,\n",
       "   91.140642303433,\n",
       "   91.38981173864894,\n",
       "   91.140642303433],\n",
       "  'val_acc': [81.03448275862068,\n",
       "   85.26645768025078,\n",
       "   90.9090909090909,\n",
       "   89.65517241379311,\n",
       "   90.59561128526646,\n",
       "   91.06583072100314,\n",
       "   90.9090909090909,\n",
       "   91.53605015673982,\n",
       "   91.53605015673982,\n",
       "   91.69278996865204,\n",
       "   92.16300940438872,\n",
       "   91.69278996865204,\n",
       "   92.16300940438872,\n",
       "   91.84952978056427,\n",
       "   92.16300940438872,\n",
       "   92.47648902821317,\n",
       "   92.16300940438872,\n",
       "   92.6332288401254,\n",
       "   92.16300940438872,\n",
       "   92.47648902821317,\n",
       "   92.47648902821317,\n",
       "   92.94670846394985,\n",
       "   92.47648902821317,\n",
       "   92.31974921630093,\n",
       "   92.94670846394985,\n",
       "   92.47648902821317,\n",
       "   92.47648902821317,\n",
       "   92.47648902821317,\n",
       "   92.78996865203762,\n",
       "   92.78996865203762,\n",
       "   92.78996865203762,\n",
       "   92.78996865203762,\n",
       "   92.78996865203762,\n",
       "   92.47648902821317,\n",
       "   92.94670846394985,\n",
       "   92.47648902821317,\n",
       "   92.78996865203762,\n",
       "   93.10344827586206,\n",
       "   92.78996865203762,\n",
       "   93.10344827586206,\n",
       "   93.10344827586206,\n",
       "   92.94670846394985,\n",
       "   93.2601880877743,\n",
       "   93.10344827586206,\n",
       "   93.10344827586206,\n",
       "   93.2601880877743,\n",
       "   93.10344827586206,\n",
       "   93.10344827586206,\n",
       "   92.94670846394985,\n",
       "   93.10344827586206,\n",
       "   93.2601880877743,\n",
       "   93.10344827586206,\n",
       "   93.10344827586206,\n",
       "   93.2601880877743,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.8871473354232,\n",
       "   93.10344827586206,\n",
       "   93.57366771159874,\n",
       "   93.57366771159874,\n",
       "   93.57366771159874,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.57366771159874,\n",
       "   93.8871473354232,\n",
       "   93.8871473354232,\n",
       "   93.57366771159874,\n",
       "   93.57366771159874,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.41692789968653,\n",
       "   93.73040752351098,\n",
       "   93.8871473354232,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.8871473354232,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.8871473354232,\n",
       "   93.8871473354232,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.8871473354232,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.73040752351098,\n",
       "   93.41692789968653,\n",
       "   93.41692789968653,\n",
       "   93.41692789968653,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.41692789968653,\n",
       "   93.8871473354232,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.73040752351098,\n",
       "   93.41692789968653,\n",
       "   93.57366771159874,\n",
       "   93.8871473354232,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.8871473354232,\n",
       "   93.73040752351098,\n",
       "   93.8871473354232,\n",
       "   93.8871473354232,\n",
       "   93.8871473354232,\n",
       "   93.73040752351098,\n",
       "   93.8871473354232,\n",
       "   93.8871473354232,\n",
       "   93.8871473354232,\n",
       "   93.8871473354232,\n",
       "   93.41692789968653,\n",
       "   93.8871473354232,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.8871473354232,\n",
       "   93.73040752351098,\n",
       "   94.04388714733543,\n",
       "   93.73040752351098,\n",
       "   93.8871473354232,\n",
       "   93.57366771159874,\n",
       "   93.57366771159874,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.8871473354232,\n",
       "   93.8871473354232,\n",
       "   93.41692789968653,\n",
       "   93.57366771159874,\n",
       "   93.41692789968653,\n",
       "   93.57366771159874,\n",
       "   93.73040752351098,\n",
       "   93.8871473354232,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.8871473354232,\n",
       "   93.8871473354232,\n",
       "   93.41692789968653,\n",
       "   93.8871473354232,\n",
       "   93.8871473354232,\n",
       "   93.8871473354232,\n",
       "   93.41692789968653,\n",
       "   93.8871473354232,\n",
       "   93.57366771159874,\n",
       "   94.04388714733543,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.57366771159874,\n",
       "   93.57366771159874,\n",
       "   93.8871473354232,\n",
       "   94.20062695924764,\n",
       "   94.04388714733543,\n",
       "   94.04388714733543,\n",
       "   94.04388714733543,\n",
       "   94.04388714733543,\n",
       "   93.8871473354232,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.8871473354232,\n",
       "   93.2601880877743,\n",
       "   93.41692789968653,\n",
       "   93.73040752351098,\n",
       "   93.8871473354232,\n",
       "   93.57366771159874,\n",
       "   93.41692789968653,\n",
       "   93.57366771159874,\n",
       "   93.8871473354232,\n",
       "   93.8871473354232,\n",
       "   94.20062695924764,\n",
       "   93.73040752351098,\n",
       "   93.8871473354232,\n",
       "   94.04388714733543,\n",
       "   93.57366771159874,\n",
       "   93.2601880877743,\n",
       "   93.8871473354232,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.57366771159874,\n",
       "   93.8871473354232,\n",
       "   94.04388714733543,\n",
       "   93.73040752351098,\n",
       "   94.04388714733543,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.8871473354232,\n",
       "   93.73040752351098,\n",
       "   94.04388714733543,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.8871473354232,\n",
       "   94.04388714733543,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.73040752351098,\n",
       "   94.04388714733543,\n",
       "   93.41692789968653,\n",
       "   93.8871473354232,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.8871473354232,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.41692789968653,\n",
       "   93.2601880877743,\n",
       "   93.41692789968653,\n",
       "   93.57366771159874,\n",
       "   93.2601880877743,\n",
       "   94.04388714733543,\n",
       "   93.41692789968653,\n",
       "   93.41692789968653,\n",
       "   94.20062695924764,\n",
       "   93.57366771159874,\n",
       "   93.8871473354232,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.73040752351098,\n",
       "   93.8871473354232,\n",
       "   93.57366771159874,\n",
       "   93.8871473354232,\n",
       "   93.8871473354232,\n",
       "   94.04388714733543,\n",
       "   94.04388714733543,\n",
       "   94.04388714733543,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.73040752351098,\n",
       "   93.41692789968653,\n",
       "   93.57366771159874,\n",
       "   93.41692789968653,\n",
       "   93.57366771159874,\n",
       "   93.57366771159874,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.41692789968653,\n",
       "   93.57366771159874,\n",
       "   93.57366771159874,\n",
       "   93.2601880877743,\n",
       "   93.73040752351098,\n",
       "   93.8871473354232,\n",
       "   93.8871473354232,\n",
       "   93.73040752351098,\n",
       "   93.8871473354232,\n",
       "   93.41692789968653,\n",
       "   93.41692789968653,\n",
       "   93.57366771159874,\n",
       "   93.2601880877743,\n",
       "   93.73040752351098,\n",
       "   93.73040752351098,\n",
       "   94.04388714733543,\n",
       "   93.41692789968653,\n",
       "   93.73040752351098,\n",
       "   93.41692789968653,\n",
       "   93.73040752351098,\n",
       "   93.57366771159874,\n",
       "   93.57366771159874,\n",
       "   93.57366771159874,\n",
       "   93.41692789968653,\n",
       "   93.10344827586206,\n",
       "   93.41692789968653,\n",
       "   93.41692789968653,\n",
       "   93.41692789968653,\n",
       "   93.73040752351098,\n",
       "   93.8871473354232,\n",
       "   93.2601880877743]},\n",
       " 'best_train_metrics': {'loss': 0.27890636239733013,\n",
       "  'accuracy': 91.30675526024363,\n",
       "  'precision': 0.8975945017182131,\n",
       "  'recall': 0.8878314072059823,\n",
       "  'f1': 0.8926862611073137,\n",
       "  'auroc': 0.9353977616767072},\n",
       " 'best_val_metrics': {'loss': 0.22194582630287518,\n",
       "  'accuracy': 93.73040752351098,\n",
       "  'precision': 0.9230769230769231,\n",
       "  'recall': 0.9230769230769231,\n",
       "  'f1': 0.9230769230769231,\n",
       "  'auroc': 0.9487789987789988},\n",
       " 'best_epoch': 226,\n",
       " 'total_epochs': 300,\n",
       " 'model': Sequential(\n",
       "   (0): Linear(in_features=11, out_features=64, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Dropout(p=0.4, inplace=False)\n",
       "   (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "   (4): ReLU()\n",
       "   (5): Dropout(p=0.4, inplace=False)\n",
       "   (6): Linear(in_features=32, out_features=16, bias=True)\n",
       "   (7): ReLU()\n",
       "   (8): Dropout(p=0.1, inplace=False)\n",
       "   (9): Linear(in_features=16, out_features=2, bias=True)\n",
       " )}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0e00a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESULTADOS DEL CONJUNTO DE PRUEBA (usando el mejor modelo):\n",
      "Pérdida: 0.3057, Accuracy: 90.27%, Precision: 0.8722, Recall: 0.8922, F1: 0.8821, AUROC: 0.9118\n"
     ]
    }
   ],
   "source": [
    "# Load best model and evaluate on test set\n",
    "mlp.load_state_dict(torch.load('best_model.pth'))\n",
    "test_loss, test_acc, test_labels, test_preds, test_probs = eval_epoch(mlp, test_loader, criterion, device)\n",
    "test_precision, test_recall, test_f1, test_auroc = _compute_metrics(test_labels, test_preds, test_probs)\n",
    "\n",
    "print(f\"\\nRESULTADOS DEL CONJUNTO DE PRUEBA (usando el mejor modelo):\")\n",
    "print(f\"Pérdida: {test_loss:.4f}, Accuracy: {test_acc:.2f}%, Precision: {test_precision:.4f}, \"\n",
    "      f\"Recall: {test_recall:.4f}, F1: {test_f1:.4f}, AUROC: {test_auroc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451540fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b901028",
   "metadata": {},
   "source": [
    "### PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae808eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f179ca72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:16:10,723] A new study created in memory with name: no-name-1204d39b-7896-4ad9-8d81-fe1897d1284c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PSO Hyperparameter Optimization\n",
      "Fixed Architecture: 3 hidden layers, ReLU activation, Adam optimizer\n",
      "Input features: 11\n",
      "Training samples: 3612\n",
      "Validation samples: 638\n",
      "PSO Settings: 20 particles, 100 trials\n",
      "PSO Coefficients: inertia=0.7, cognitive=1.4, social=1.4\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.224977:   1%|          | 1/100 [00:30<49:43, 30.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:16:40,852] Trial 0 finished with value: 0.22497667563746343 and parameters: {'use_batch_norm': False, 'learning_rate': 0.001570297088405539, 'weight_decay': 0.0002481040974867811, 'batch_size': 32, 'hidden_size_0': 64, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.5330880728874676, 'dropout_rate_1': 0.40055750587160444, 'dropout_rate_2': 0.4540362888980227}. Best is trial 0 with value: 0.22497667563746343.\n",
      "Trial 0/100 | Best value: 0.2250 | Best trial: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.22448:   2%|▏         | 2/100 [00:50<39:36, 24.25s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:17:00,988] Trial 1 finished with value: 0.22447958130821538 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00314288089084011, 'weight_decay': 7.068974950624607e-06, 'batch_size': 32, 'hidden_size_0': 64, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.3159725093210579, 'dropout_rate_1': 0.24561457009902096, 'dropout_rate_2': 0.40592644736118977}. Best is trial 1 with value: 0.22447958130821538.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.22448:   3%|▎         | 3/100 [01:14<39:16, 24.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:17:25,343] Trial 2 finished with value: 0.23163810185504183 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00012562773503807024, 'weight_decay': 6.672367170464208e-05, 'batch_size': 112, 'hidden_size_0': 64, 'hidden_size_1': 48, 'hidden_size_2': 32, 'dropout_rate_0': 0.12322520635999887, 'dropout_rate_1': 0.40377242595071916, 'dropout_rate_2': 0.18526206184364577}. Best is trial 1 with value: 0.22447958130821538.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.22448:   4%|▍         | 4/100 [01:30<33:40, 21.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:17:41,397] Trial 3 finished with value: 0.22796381493814313 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00788671412999049, 'weight_decay': 0.0017123375973163992, 'batch_size': 48, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.16101911742238942, 'dropout_rate_1': 0.34758845505563507, 'dropout_rate_2': 0.1171942605576092}. Best is trial 1 with value: 0.22447958130821538.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.224466:   5%|▌         | 5/100 [01:55<35:45, 22.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:18:06,711] Trial 4 finished with value: 0.22446623771541918 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0009717775305059633, 'weight_decay': 1.7654048052495086e-05, 'batch_size': 80, 'hidden_size_0': 160, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.48756641168055725, 'dropout_rate_1': 0.5697494707820946, 'dropout_rate_2': 0.5474136752138244}. Best is trial 4 with value: 0.22446623771541918.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.224466:   6%|▌         | 6/100 [04:31<1:46:10, 67.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:20:42,201] Trial 5 finished with value: 0.26557335290228684 and parameters: {'use_batch_norm': False, 'learning_rate': 1.8427970406864546e-05, 'weight_decay': 6.0803901902966035e-06, 'batch_size': 16, 'hidden_size_0': 96, 'hidden_size_1': 48, 'hidden_size_2': 16, 'dropout_rate_0': 0.5143687545759646, 'dropout_rate_1': 0.2783766633467947, 'dropout_rate_2': 0.2404672548436904}. Best is trial 4 with value: 0.22446623771541918.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.224466:   7%|▋         | 7/100 [04:43<1:16:55, 49.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:20:54,479] Trial 6 finished with value: 0.22703866305582948 and parameters: {'use_batch_norm': True, 'learning_rate': 0.002550298070162891, 'weight_decay': 1.987021538542864e-06, 'batch_size': 128, 'hidden_size_0': 224, 'hidden_size_1': 48, 'hidden_size_2': 16, 'dropout_rate_0': 0.5077307142274171, 'dropout_rate_1': 0.45342867192380854, 'dropout_rate_2': 0.46450358402049363}. Best is trial 4 with value: 0.22446623771541918.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.224466:   8%|▊         | 8/100 [05:10<1:05:03, 42.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:21:21,490] Trial 7 finished with value: 0.23579179334416284 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0001189589673755355, 'weight_decay': 2.907208890659845e-06, 'batch_size': 112, 'hidden_size_0': 160, 'hidden_size_1': 64, 'hidden_size_2': 16, 'dropout_rate_0': 0.2554911608578311, 'dropout_rate_1': 0.2625916610133735, 'dropout_rate_2': 0.464803089169032}. Best is trial 4 with value: 0.22446623771541918.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.224466:   9%|▉         | 9/100 [05:25<50:59, 33.63s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:21:35,764] Trial 8 finished with value: 0.23393163738953282 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00026100256506134784, 'weight_decay': 3.0086868214458464e-06, 'batch_size': 96, 'hidden_size_0': 224, 'hidden_size_1': 112, 'hidden_size_2': 96, 'dropout_rate_0': 0.34689779818219535, 'dropout_rate_1': 0.36136641469099706, 'dropout_rate_2': 0.31377050917927485}. Best is trial 4 with value: 0.22446623771541918.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.224466:  10%|█         | 10/100 [06:14<57:53, 38.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:22:25,482] Trial 9 finished with value: 0.26664516493257684 and parameters: {'use_batch_norm': False, 'learning_rate': 1.2424747083660186e-05, 'weight_decay': 0.00035127047262708476, 'batch_size': 48, 'hidden_size_0': 160, 'hidden_size_1': 160, 'hidden_size_2': 32, 'dropout_rate_0': 0.30519146151781484, 'dropout_rate_1': 0.4777755692715243, 'dropout_rate_2': 0.21439908274581124}. Best is trial 4 with value: 0.22446623771541918.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.224466:  11%|█         | 11/100 [06:39<51:05, 34.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:22:50,508] Trial 10 finished with value: 0.2547595432746373 and parameters: {'use_batch_norm': False, 'learning_rate': 3.0455368715396772e-05, 'weight_decay': 0.005233480488540089, 'batch_size': 112, 'hidden_size_0': 192, 'hidden_size_1': 176, 'hidden_size_2': 112, 'dropout_rate_0': 0.19328502944301792, 'dropout_rate_1': 0.5462794992449889, 'dropout_rate_2': 0.3696711209578254}. Best is trial 4 with value: 0.22446623771541918.\n",
      "Trial 10/100 | Best value: 0.2245 | Best trial: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.224466:  12%|█▏        | 12/100 [07:23<54:42, 37.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:23:34,344] Trial 11 finished with value: 0.23694553251924186 and parameters: {'use_batch_norm': False, 'learning_rate': 8.995191735587162e-05, 'weight_decay': 2.7555462077796614e-06, 'batch_size': 32, 'hidden_size_0': 128, 'hidden_size_1': 112, 'hidden_size_2': 112, 'dropout_rate_0': 0.10347606526559536, 'dropout_rate_1': 0.35537365128878284, 'dropout_rate_2': 0.3087055015743895}. Best is trial 4 with value: 0.22446623771541918.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.224466:  13%|█▎        | 13/100 [08:24<1:04:25, 44.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:24:35,176] Trial 12 finished with value: 0.2327718493706754 and parameters: {'use_batch_norm': True, 'learning_rate': 0.00010300196600986775, 'weight_decay': 0.005910698619088547, 'batch_size': 48, 'hidden_size_0': 160, 'hidden_size_1': 128, 'hidden_size_2': 48, 'dropout_rate_0': 0.5858910413604803, 'dropout_rate_1': 0.5812236474710556, 'dropout_rate_2': 0.22589114791268208}. Best is trial 4 with value: 0.22446623771541918.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.224466:  14%|█▍        | 14/100 [09:02<1:00:51, 42.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:25:13,096] Trial 13 finished with value: 0.24189017213250402 and parameters: {'use_batch_norm': True, 'learning_rate': 7.153547794693153e-05, 'weight_decay': 1.4045842344024705e-06, 'batch_size': 80, 'hidden_size_0': 160, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.23932323211830572, 'dropout_rate_1': 0.5541329429833268, 'dropout_rate_2': 0.21978094533348622}. Best is trial 4 with value: 0.22446623771541918.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.224466:  15%|█▌        | 15/100 [09:10<45:38, 32.22s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:25:21,590] Trial 14 finished with value: 0.23485317134931918 and parameters: {'use_batch_norm': False, 'learning_rate': 0.009056311714376347, 'weight_decay': 9.294394155644998e-06, 'batch_size': 96, 'hidden_size_0': 224, 'hidden_size_1': 48, 'hidden_size_2': 48, 'dropout_rate_0': 0.28389156635962665, 'dropout_rate_1': 0.41615291529678977, 'dropout_rate_2': 0.4167648553804474}. Best is trial 4 with value: 0.22446623771541918.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.224466:  16%|█▌        | 16/100 [09:51<48:35, 34.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:26:02,055] Trial 15 finished with value: 0.22743851254726277 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0032055863990707507, 'weight_decay': 1.91920011015619e-05, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.10829391446392808, 'dropout_rate_1': 0.3560465291496405, 'dropout_rate_2': 0.21324788759896898}. Best is trial 4 with value: 0.22446623771541918.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.223851:  17%|█▋        | 17/100 [10:07<40:19, 29.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:26:18,296] Trial 16 finished with value: 0.2238511460421601 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0011825328508422654, 'weight_decay': 3.523233163198316e-05, 'batch_size': 128, 'hidden_size_0': 64, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.5623468091392814, 'dropout_rate_1': 0.5386696766904905, 'dropout_rate_2': 0.2289708138575778}. Best is trial 16 with value: 0.2238511460421601.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  18%|█▊        | 18/100 [11:29<1:01:29, 44.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:27:40,167] Trial 17 finished with value: 0.21915525943040848 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00046302286171220994, 'weight_decay': 0.0001314021022620739, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.416550728636634, 'dropout_rate_1': 0.2695148955243504, 'dropout_rate_2': 0.2746047873063304}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  19%|█▉        | 19/100 [11:46<49:29, 36.66s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:27:57,421] Trial 18 finished with value: 0.22008320088950817 and parameters: {'use_batch_norm': False, 'learning_rate': 0.004584154780136381, 'weight_decay': 0.0013167465326936148, 'batch_size': 96, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.5492770942635397, 'dropout_rate_1': 0.403214529829795, 'dropout_rate_2': 0.10459852580831483}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  20%|██        | 20/100 [12:25<49:49, 37.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:28:36,426] Trial 19 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 1.0355826161899173e-05, 'weight_decay': 4.3977668944839625e-06, 'batch_size': 80, 'hidden_size_0': 192, 'hidden_size_1': 128, 'hidden_size_2': 32, 'dropout_rate_0': 0.45608961067376796, 'dropout_rate_1': 0.21862454374840004, 'dropout_rate_2': 0.26269984907963384}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  21%|██        | 21/100 [13:24<57:32, 43.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:29:34,920] Trial 20 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 1e-05, 'weight_decay': 0.0065422619969271855, 'batch_size': 64, 'hidden_size_0': 64, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.1667722624279553, 'dropout_rate_1': 0.5236972298962623, 'dropout_rate_2': 0.2994590196670228}. Best is trial 17 with value: 0.21915525943040848.\n",
      "Trial 20/100 | Best value: 0.2192 | Best trial: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  22%|██▏       | 22/100 [13:35<44:11, 34.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:29:46,279] Trial 21 finished with value: 0.23199253802576036 and parameters: {'use_batch_norm': True, 'learning_rate': 0.003563657203296898, 'weight_decay': 1e-06, 'batch_size': 112, 'hidden_size_0': 128, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.1259349171282094, 'dropout_rate_1': 0.1324139813826067, 'dropout_rate_2': 0.3796376278805437}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  23%|██▎       | 23/100 [14:22<48:48, 38.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:30:33,705] Trial 22 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 1e-05, 'weight_decay': 1e-06, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.2988849983028902, 'dropout_rate_1': 0.49496043174518944, 'dropout_rate_2': 0.1}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  24%|██▍       | 24/100 [15:14<53:09, 41.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:31:24,873] Trial 23 finished with value: 0.24504681137101403 and parameters: {'use_batch_norm': True, 'learning_rate': 0.00423867551029425, 'weight_decay': 0.0029718019018030854, 'batch_size': 16, 'hidden_size_0': 64, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.41793821507168316}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  25%|██▌       | 25/100 [16:07<56:53, 45.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:32:18,657] Trial 24 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 1e-05, 'weight_decay': 1e-06, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.1, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.2664274119883271}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  26%|██▌       | 26/100 [17:17<1:04:59, 52.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:33:28,095] Trial 25 finished with value: 0.22729290426244556 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0027867921368990036, 'weight_decay': 1e-06, 'batch_size': 32, 'hidden_size_0': 64, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.5802494922923349, 'dropout_rate_2': 0.5427807685092548}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  27%|██▋       | 27/100 [17:51<57:28, 47.24s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:34:02,626] Trial 26 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 0.0032888581415956093, 'weight_decay': 0.006020491677627196, 'batch_size': 48, 'hidden_size_0': 128, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.3484356280828175, 'dropout_rate_1': 0.1064195152913402, 'dropout_rate_2': 0.43518145050151513}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  28%|██▊       | 28/100 [18:29<53:04, 44.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:34:39,826] Trial 27 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 1e-05, 'weight_decay': 1e-06, 'batch_size': 96, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.4595619812886017, 'dropout_rate_2': 0.1793639336768551}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  29%|██▉       | 29/100 [19:18<54:01, 45.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:35:28,788] Trial 28 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 1e-05, 'weight_decay': 0.004427296050049137, 'batch_size': 128, 'hidden_size_0': 64, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.2573640185462358, 'dropout_rate_1': 0.1, 'dropout_rate_2': 0.5419814981274753}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  30%|███       | 30/100 [20:26<1:01:23, 52.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:36:37,671] Trial 29 finished with value: 0.2263828073409284 and parameters: {'use_batch_norm': False, 'learning_rate': 0.002277178139587035, 'weight_decay': 1e-06, 'batch_size': 16, 'hidden_size_0': 96, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.49280584666386246, 'dropout_rate_1': 0.47468631209567136, 'dropout_rate_2': 0.24345509002873972}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  31%|███       | 31/100 [20:51<50:54, 44.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:37:02,461] Trial 30 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 1e-05, 'weight_decay': 0.007498760799263817, 'batch_size': 128, 'hidden_size_0': 192, 'hidden_size_1': 112, 'hidden_size_2': 96, 'dropout_rate_0': 0.3089008539829792, 'dropout_rate_1': 0.16819399920863642, 'dropout_rate_2': 0.1}. Best is trial 17 with value: 0.21915525943040848.\n",
      "Trial 30/100 | Best value: 0.2192 | Best trial: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  32%|███▏      | 32/100 [22:11<1:02:20, 55.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:38:22,499] Trial 31 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 1e-05, 'weight_decay': 1e-06, 'batch_size': 48, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.2682859425195047, 'dropout_rate_1': 0.25167634231699076, 'dropout_rate_2': 0.4431560130958896}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  33%|███▎      | 33/100 [24:47<1:35:07, 85.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:40:58,126] Trial 32 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 1e-05, 'weight_decay': 1e-06, 'batch_size': 16, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.45403636406739456, 'dropout_rate_1': 0.42640846629352464, 'dropout_rate_2': 0.47756954683743247}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  34%|███▍      | 34/100 [25:58<1:28:54, 80.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:42:08,771] Trial 33 finished with value: 0.25223739118224775 and parameters: {'use_batch_norm': True, 'learning_rate': 1e-05, 'weight_decay': 0.005507156474816285, 'batch_size': 48, 'hidden_size_0': 192, 'hidden_size_1': 128, 'hidden_size_2': 16, 'dropout_rate_0': 0.1, 'dropout_rate_1': 0.30671033807443193, 'dropout_rate_2': 0.2272049113193529}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  35%|███▌      | 35/100 [28:07<1:43:19, 95.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:44:18,083] Trial 34 finished with value: 0.23719732799686982 and parameters: {'use_batch_norm': True, 'learning_rate': 0.001634195782424388, 'weight_decay': 0.005122999425641222, 'batch_size': 16, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.15771685000111718, 'dropout_rate_1': 0.22523999051961618, 'dropout_rate_2': 0.6}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  36%|███▌      | 36/100 [28:46<1:23:49, 78.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:44:57,513] Trial 35 finished with value: 0.22879625763452166 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00027669064767460536, 'weight_decay': 0.0003006970834940706, 'batch_size': 64, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.1, 'dropout_rate_1': 0.31950809627286736, 'dropout_rate_2': 0.14847507390261896}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  37%|███▋      | 37/100 [29:19<1:07:55, 64.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:45:29,798] Trial 36 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 1e-05, 'weight_decay': 1e-06, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.1361836130963031, 'dropout_rate_2': 0.1}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  38%|███▊      | 38/100 [31:30<1:27:35, 84.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:47:41,395] Trial 37 finished with value: 0.23421791522854174 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0003155091669542064, 'weight_decay': 0.006929828549174728, 'batch_size': 16, 'hidden_size_0': 96, 'hidden_size_1': 96, 'hidden_size_2': 16, 'dropout_rate_0': 0.5763021726649357, 'dropout_rate_1': 0.17696308842782765, 'dropout_rate_2': 0.36721886872183607}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  39%|███▉      | 39/100 [32:08<1:11:56, 70.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:48:19,476] Trial 38 finished with value: 0.2287685368969149 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0014548723610576493, 'weight_decay': 0.0017425024469158786, 'batch_size': 32, 'hidden_size_0': 128, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.19986969115277736, 'dropout_rate_1': 0.3556305069404665, 'dropout_rate_2': 0.31954894190237576}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  40%|████      | 40/100 [34:56<1:39:49, 99.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:51:07,140] Trial 39 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 1e-05, 'weight_decay': 0.0003508917315363987, 'batch_size': 16, 'hidden_size_0': 64, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.3631125387004375, 'dropout_rate_1': 0.556435225215245, 'dropout_rate_2': 0.1}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  41%|████      | 41/100 [35:24<1:17:03, 78.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:51:35,427] Trial 40 finished with value: 0.22643928846408581 and parameters: {'use_batch_norm': False, 'learning_rate': 0.002583873299198808, 'weight_decay': 0.0009380966579918435, 'batch_size': 48, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.10968217714452935, 'dropout_rate_1': 0.4464287385062495, 'dropout_rate_2': 0.3028522523420423}. Best is trial 17 with value: 0.21915525943040848.\n",
      "Trial 40/100 | Best value: 0.2192 | Best trial: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  42%|████▏     | 42/100 [35:57<1:02:23, 64.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:52:07,732] Trial 41 finished with value: 0.22888834003744454 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0015143295307067308, 'weight_decay': 0.0001713363727370401, 'batch_size': 48, 'hidden_size_0': 96, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.3392868680343898, 'dropout_rate_1': 0.3121874044143348, 'dropout_rate_2': 0.23604855269448585}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  43%|████▎     | 43/100 [36:41<55:33, 58.48s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:52:52,033] Trial 42 finished with value: 0.2286033921854623 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00018611612050275028, 'weight_decay': 0.00010010806969233136, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.4062729768651972, 'dropout_rate_1': 0.45941687614258503, 'dropout_rate_2': 0.2601043154145273}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  44%|████▍     | 44/100 [37:12<46:53, 50.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:53:23,058] Trial 43 finished with value: 0.22745030852133952 and parameters: {'use_batch_norm': False, 'learning_rate': 0.005796300791631169, 'weight_decay': 0.0025379982945656567, 'batch_size': 64, 'hidden_size_0': 64, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.3188636321088575, 'dropout_rate_1': 0.4833639076661508, 'dropout_rate_2': 0.3935150912532972}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  45%|████▌     | 45/100 [38:00<45:22, 49.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:54:10,829] Trial 44 finished with value: 0.22394087695776482 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0009882367217893325, 'weight_decay': 7.054074383234907e-05, 'batch_size': 48, 'hidden_size_0': 192, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.5513380947271347, 'dropout_rate_2': 0.1452140284254337}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  46%|████▌     | 46/100 [38:58<46:57, 52.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:55:09,263] Trial 45 finished with value: 0.2220604523876244 and parameters: {'use_batch_norm': True, 'learning_rate': 0.003497237168711582, 'weight_decay': 4.664256939186737e-06, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.37128678690669326, 'dropout_rate_1': 0.5333308761747229, 'dropout_rate_2': 0.49943372499189287}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  47%|████▋     | 47/100 [40:06<50:21, 57.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:56:17,532] Trial 46 finished with value: 0.2242430025787563 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0015534446109665544, 'weight_decay': 0.0007082072743610736, 'batch_size': 16, 'hidden_size_0': 64, 'hidden_size_1': 64, 'hidden_size_2': 32, 'dropout_rate_0': 0.3558170277065307, 'dropout_rate_1': 0.1, 'dropout_rate_2': 0.39194138332449746}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  48%|████▊     | 48/100 [40:31<41:01, 47.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:56:42,333] Trial 47 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 0.0006705749813874794, 'weight_decay': 2.188318585009008e-05, 'batch_size': 48, 'hidden_size_0': 96, 'hidden_size_1': 96, 'hidden_size_2': 32, 'dropout_rate_0': 0.49506535160538645, 'dropout_rate_1': 0.407335395365468, 'dropout_rate_2': 0.2327121894847978}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  49%|████▉     | 49/100 [41:19<40:26, 47.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:57:30,437] Trial 48 finished with value: 0.2337995607837988 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0004903300710082308, 'weight_decay': 0.0033850490111503335, 'batch_size': 48, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.3424902422655571, 'dropout_rate_1': 0.3820672941190082, 'dropout_rate_2': 0.5201510477171071}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  50%|█████     | 50/100 [41:50<35:32, 42.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 19:58:01,569] Trial 49 finished with value: 0.22466197773393792 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0023496918833667887, 'weight_decay': 8.70923369091475e-05, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.5211123789048386, 'dropout_rate_1': 0.4368206996867985, 'dropout_rate_2': 0.2956671159704724}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  51%|█████     | 51/100 [44:04<57:07, 69.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:00:15,209] Trial 50 finished with value: 0.24276166528369938 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00014066757703731135, 'weight_decay': 0.0068154087647488365, 'batch_size': 16, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.4994108127312792, 'dropout_rate_1': 0.3801528502114364, 'dropout_rate_2': 0.37573733159896117}. Best is trial 17 with value: 0.21915525943040848.\n",
      "Trial 50/100 | Best value: 0.2192 | Best trial: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  52%|█████▏    | 52/100 [45:24<58:25, 73.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:01:35,464] Trial 51 finished with value: 0.2245944674392479 and parameters: {'use_batch_norm': True, 'learning_rate': 0.000403892170772524, 'weight_decay': 0.00016741465718547236, 'batch_size': 32, 'hidden_size_0': 64, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.39959012555689827, 'dropout_rate_1': 0.31316325068187273, 'dropout_rate_2': 0.27764376510278815}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  53%|█████▎    | 53/100 [45:53<46:52, 59.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:02:04,489] Trial 52 finished with value: 0.22909909673619047 and parameters: {'use_batch_norm': True, 'learning_rate': 0.00045217745777965474, 'weight_decay': 0.004553828691737899, 'batch_size': 80, 'hidden_size_0': 160, 'hidden_size_1': 64, 'hidden_size_2': 64, 'dropout_rate_0': 0.36318660461524777, 'dropout_rate_1': 0.4512786795164507, 'dropout_rate_2': 0.529039833653181}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  54%|█████▍    | 54/100 [48:27<1:07:22, 87.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:04:37,834] Trial 53 finished with value: 0.23772788818540244 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00029793819552079333, 'weight_decay': 0.006838896767346671, 'batch_size': 16, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.31352416574090464, 'dropout_rate_2': 0.26868671067386973}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  55%|█████▌    | 55/100 [49:15<57:02, 76.05s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:05:26,271] Trial 54 finished with value: 0.2272586134907594 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0014452753877599992, 'weight_decay': 0.00029783849676515844, 'batch_size': 32, 'hidden_size_0': 256, 'hidden_size_1': 80, 'hidden_size_2': 64, 'dropout_rate_0': 0.5278500400891806, 'dropout_rate_1': 0.3661100386053978, 'dropout_rate_2': 0.36698667196955403}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  56%|█████▌    | 56/100 [49:56<48:01, 65.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:06:07,134] Trial 55 finished with value: 0.21983818079236905 and parameters: {'use_batch_norm': True, 'learning_rate': 0.002352200968359488, 'weight_decay': 1e-06, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.5145189349065096, 'dropout_rate_1': 0.2901007774226447, 'dropout_rate_2': 0.16936554700349044}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  57%|█████▋    | 57/100 [50:35<41:09, 57.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:06:45,747] Trial 56 finished with value: 0.22199969603256745 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0014504840270670013, 'weight_decay': 0.00012866658232663807, 'batch_size': 16, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.3268980991316703, 'dropout_rate_1': 0.1182496347318912, 'dropout_rate_2': 0.3665372882906336}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  58%|█████▊    | 58/100 [52:02<46:31, 66.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:08:13,304] Trial 57 finished with value: 0.22384854782150831 and parameters: {'use_batch_norm': True, 'learning_rate': 0.00026925659377022526, 'weight_decay': 0.001852807952885424, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.5398034089573901, 'dropout_rate_1': 0.29648656363233183, 'dropout_rate_2': 0.34830120689968}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  59%|█████▉    | 59/100 [53:30<49:43, 72.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:09:40,757] Trial 58 finished with value: 0.23429250469588933 and parameters: {'use_batch_norm': True, 'learning_rate': 0.00045255189240458104, 'weight_decay': 0.00164969338072753, 'batch_size': 16, 'hidden_size_0': 96, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.20523238491318413, 'dropout_rate_1': 0.31249925358412284, 'dropout_rate_2': 0.23393836359479495}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  60%|██████    | 60/100 [53:56<39:10, 58.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:10:06,810] Trial 59 finished with value: 0.22665671765991138 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0005527199067689538, 'weight_decay': 0.00028782080292463834, 'batch_size': 96, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.3780306548669525, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.28542008751118597}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  61%|██████    | 61/100 [55:00<39:13, 60.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:11:10,842] Trial 60 finished with value: 0.228545499726149 and parameters: {'use_batch_norm': True, 'learning_rate': 0.002963213486803652, 'weight_decay': 1e-06, 'batch_size': 16, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.29745628116563005, 'dropout_rate_2': 0.3226285075182659}. Best is trial 17 with value: 0.21915525943040848.\n",
      "Trial 60/100 | Best value: 0.2192 | Best trial: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  62%|██████▏   | 62/100 [56:17<41:28, 65.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:12:28,321] Trial 61 finished with value: 0.23031010808055305 and parameters: {'use_batch_norm': True, 'learning_rate': 0.001023606789612053, 'weight_decay': 0.0002229329093639716, 'batch_size': 16, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.5316178155781521, 'dropout_rate_1': 0.4256782365883566, 'dropout_rate_2': 0.2141342851188659}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  63%|██████▎   | 63/100 [58:02<47:38, 77.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:14:13,062] Trial 62 finished with value: 0.2223507142786322 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00031366015156767985, 'weight_decay': 0.00017548090318894748, 'batch_size': 16, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.4910136764626556, 'dropout_rate_1': 0.38791169280495846, 'dropout_rate_2': 0.39074050281187583}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  64%|██████▍   | 64/100 [58:12<34:16, 57.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:14:23,174] Trial 63 finished with value: 0.22617526894265955 and parameters: {'use_batch_norm': True, 'learning_rate': 0.003979928099348961, 'weight_decay': 0.0012616588227834938, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.18717374881345217, 'dropout_rate_1': 0.20302305069273668, 'dropout_rate_2': 0.22046071191089658}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.219155:  65%|██████▌   | 65/100 [59:48<40:04, 68.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:15:58,895] Trial 64 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 0.0011061511430079992, 'weight_decay': 0.00012830206480373324, 'batch_size': 16, 'hidden_size_0': 160, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.4883237381899796, 'dropout_rate_1': 0.42005622801960674, 'dropout_rate_2': 0.2087426386103608}. Best is trial 17 with value: 0.21915525943040848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 65. Best value: 0.218943:  66%|██████▌   | 66/100 [1:00:41<36:17, 64.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:16:52,122] Trial 65 finished with value: 0.2189429696637635 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0020999607547417067, 'weight_decay': 4.007792469566832e-05, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.2529343224342059, 'dropout_rate_1': 0.24480077584302706, 'dropout_rate_2': 0.20179753580965787}. Best is trial 65 with value: 0.2189429696637635.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 65. Best value: 0.218943:  67%|██████▋   | 67/100 [1:03:10<49:17, 89.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:19:21,412] Trial 66 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 1e-05, 'weight_decay': 1e-06, 'batch_size': 16, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.4435503529097481, 'dropout_rate_1': 0.3240941293488924, 'dropout_rate_2': 0.2837735815481734}. Best is trial 65 with value: 0.2189429696637635.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 65. Best value: 0.218943:  68%|██████▊   | 68/100 [1:03:57<40:54, 76.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:20:07,996] Trial 67 finished with value: 0.2382154715332118 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0002649316290174457, 'weight_decay': 6.617663889278732e-05, 'batch_size': 32, 'hidden_size_0': 192, 'hidden_size_1': 112, 'hidden_size_2': 32, 'dropout_rate_0': 0.2575485806239885, 'dropout_rate_1': 0.28484208242643905, 'dropout_rate_2': 0.3317684634682028}. Best is trial 65 with value: 0.2189429696637635.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 65. Best value: 0.218943:  69%|██████▉   | 69/100 [1:05:33<42:39, 82.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:21:44,170] Trial 68 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 0.0007960235633119985, 'weight_decay': 1e-06, 'batch_size': 16, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.46714130259812653, 'dropout_rate_1': 0.44184616328381027, 'dropout_rate_2': 0.16657651031831844}. Best is trial 65 with value: 0.2189429696637635.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  70%|███████   | 70/100 [1:06:04<33:30, 67.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:22:14,905] Trial 69 finished with value: 0.2181567822037072 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0017834147940386524, 'weight_decay': 0.00014996816784359156, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.4414358934033582, 'dropout_rate_1': 0.359193571891404, 'dropout_rate_2': 0.30420378158533334}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  71%|███████   | 71/100 [1:08:11<41:04, 84.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:24:21,784] Trial 70 finished with value: 0.22577225071229157 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0003366877171142385, 'weight_decay': 1e-06, 'batch_size': 16, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.4943722454218696, 'dropout_rate_2': 0.5423564975924311}. Best is trial 69 with value: 0.2181567822037072.\n",
      "Trial 70/100 | Best value: 0.2182 | Best trial: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  72%|███████▏  | 72/100 [1:08:39<31:44, 68.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:24:50,291] Trial 71 finished with value: 0.22670997929143308 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0007423859212649028, 'weight_decay': 0.0002488132441856311, 'batch_size': 32, 'hidden_size_0': 64, 'hidden_size_1': 48, 'hidden_size_2': 16, 'dropout_rate_0': 0.5042534277540053, 'dropout_rate_1': 0.3199708925290218, 'dropout_rate_2': 0.15931717475970647}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  73%|███████▎  | 73/100 [1:09:01<24:27, 54.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:25:12,694] Trial 72 finished with value: 0.24104252499659606 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0007700656571962869, 'weight_decay': 0.00720223919200403, 'batch_size': 96, 'hidden_size_0': 192, 'hidden_size_1': 80, 'hidden_size_2': 64, 'dropout_rate_0': 0.33663853691506046, 'dropout_rate_1': 0.4480640551382381, 'dropout_rate_2': 0.4866377819541475}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  74%|███████▍  | 74/100 [1:10:38<29:04, 67.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:26:49,571] Trial 73 finished with value: 0.236541096226175 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0006302460737874322, 'weight_decay': 0.005263587995494515, 'batch_size': 16, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.37725371508675215, 'dropout_rate_1': 0.27464949239231895, 'dropout_rate_2': 0.30465888284953757}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  75%|███████▌  | 75/100 [1:11:14<23:58, 57.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:27:24,736] Trial 74 finished with value: 0.22593434928072656 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0011358152574947977, 'weight_decay': 1e-06, 'batch_size': 48, 'hidden_size_0': 192, 'hidden_size_1': 64, 'hidden_size_2': 64, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.4638554903963863, 'dropout_rate_2': 0.16675336915016536}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  76%|███████▌  | 76/100 [1:11:37<18:55, 47.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:27:48,239] Trial 75 finished with value: 0.2218313983942274 and parameters: {'use_batch_norm': False, 'learning_rate': 0.002373489634426208, 'weight_decay': 0.00017680665447069208, 'batch_size': 64, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.2496906262931584, 'dropout_rate_2': 0.19398364696455045}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  77%|███████▋  | 77/100 [1:12:39<19:50, 51.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:28:50,410] Trial 76 finished with value: 0.22530852860791556 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0011194018875202987, 'weight_decay': 0.00022090415249780097, 'batch_size': 16, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.176344278437847, 'dropout_rate_1': 0.2091764853602323, 'dropout_rate_2': 0.45395771711977595}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  78%|███████▊  | 78/100 [1:13:18<17:33, 47.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:29:29,188] Trial 77 finished with value: 0.22521253703249658 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00048212801110242124, 'weight_decay': 1e-06, 'batch_size': 48, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.45995476396159374, 'dropout_rate_1': 0.33381561410302035, 'dropout_rate_2': 0.16613062799558256}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  79%|███████▉  | 79/100 [1:13:39<13:54, 39.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:29:49,931] Trial 78 finished with value: 0.22052714081486938 and parameters: {'use_batch_norm': False, 'learning_rate': 0.002179189202524902, 'weight_decay': 1e-06, 'batch_size': 64, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.25923983709242165, 'dropout_rate_2': 0.17963684312543565}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  80%|████████  | 80/100 [1:13:56<10:59, 33.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:30:07,216] Trial 79 finished with value: 0.22370645847626988 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0008721562566239907, 'weight_decay': 0.0002179822806039992, 'batch_size': 128, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.4149840976708675, 'dropout_rate_1': 0.5702918638114355, 'dropout_rate_2': 0.4064022751777333}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  81%|████████  | 81/100 [1:15:18<15:08, 47.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:31:29,526] Trial 80 finished with value: 0.2211094412216946 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0022224477836634395, 'weight_decay': 0.0004218544200225062, 'batch_size': 16, 'hidden_size_0': 64, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.5399390756719424, 'dropout_rate_1': 0.28337124024604876, 'dropout_rate_2': 0.42140761973958185}. Best is trial 69 with value: 0.2181567822037072.\n",
      "Trial 80/100 | Best value: 0.2182 | Best trial: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  82%|████████▏ | 82/100 [1:16:03<14:01, 46.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:32:13,777] Trial 81 finished with value: 0.22294441514814908 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0014758556383624088, 'weight_decay': 0.00010489002276122741, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.4806415038778946, 'dropout_rate_1': 0.3000949061897227, 'dropout_rate_2': 0.2476256504229219}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  83%|████████▎ | 83/100 [1:16:39<12:23, 43.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:32:50,493] Trial 82 finished with value: 0.22629968962138722 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0021950962516176886, 'weight_decay': 0.00020273625135827829, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.4882239297080558, 'dropout_rate_1': 0.3158419107710069, 'dropout_rate_2': 0.383169057000373}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  84%|████████▍ | 84/100 [1:17:27<12:00, 45.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:33:38,530] Trial 83 finished with value: 0.22492310881240987 and parameters: {'use_batch_norm': True, 'learning_rate': 0.002034358198832517, 'weight_decay': 1e-06, 'batch_size': 64, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.2723320663139003, 'dropout_rate_1': 0.1282084320978883, 'dropout_rate_2': 0.18364207685018236}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  85%|████████▌ | 85/100 [1:17:54<09:51, 39.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:34:04,951] Trial 84 finished with value: 0.2250551328436708 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0015896226836474407, 'weight_decay': 0.00011450251531205618, 'batch_size': 64, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.39708225161566196, 'dropout_rate_1': 0.24963732003473393, 'dropout_rate_2': 0.23565475261248542}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  86%|████████▌ | 86/100 [1:18:37<09:27, 40.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:34:47,945] Trial 85 finished with value: 0.2246412304828533 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0008593587195904963, 'weight_decay': 0.00020523125396990468, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.2048085987728333, 'dropout_rate_1': 0.15746901247854067, 'dropout_rate_2': 0.12377905420320778}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  87%|████████▋ | 87/100 [1:19:47<10:44, 49.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:35:58,682] Trial 86 finished with value: 0.22498620042232884 and parameters: {'use_batch_norm': True, 'learning_rate': 0.001676441892855932, 'weight_decay': 0.00031110938592178385, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.47383297683369485, 'dropout_rate_1': 0.2400496296359795, 'dropout_rate_2': 0.2847920643661542}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  88%|████████▊ | 88/100 [1:19:57<07:30, 37.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:36:08,268] Trial 87 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 0.001585016590749875, 'weight_decay': 0.00013613624751918483, 'batch_size': 128, 'hidden_size_0': 96, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.1339501385146857, 'dropout_rate_1': 0.18672270351489295, 'dropout_rate_2': 0.43545602107125986}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  89%|████████▉ | 89/100 [1:20:23<06:15, 34.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:36:34,491] Trial 88 finished with value: 0.224012452233174 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0008048338794958501, 'weight_decay': 0.002360422096000527, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.48486749445595717, 'dropout_rate_1': 0.4377412021950387, 'dropout_rate_2': 0.1503346455430397}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  90%|█████████ | 90/100 [1:21:02<05:56, 35.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:37:13,485] Trial 89 finished with value: 0.22358720572110627 and parameters: {'use_batch_norm': True, 'learning_rate': 0.001387020831508957, 'weight_decay': 0.0001939812494977024, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.3856623535523219, 'dropout_rate_1': 0.3048545824346279, 'dropout_rate_2': 0.310179447515736}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  91%|█████████ | 91/100 [1:21:46<05:43, 38.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:37:57,696] Trial 90 finished with value: 0.2250830982592786 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0018577646070626753, 'weight_decay': 0.0001046884991693676, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.39333893253347774, 'dropout_rate_1': 0.4438327858736676, 'dropout_rate_2': 0.4334310134546478}. Best is trial 69 with value: 0.2181567822037072.\n",
      "Trial 90/100 | Best value: 0.2182 | Best trial: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  92%|█████████▏| 92/100 [1:22:44<05:52, 44.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:38:55,366] Trial 91 finished with value: 0.22472131252288818 and parameters: {'use_batch_norm': True, 'learning_rate': 0.001470169088840795, 'weight_decay': 0.00011020940252196642, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.39553308421868605, 'dropout_rate_1': 0.3422347109830347, 'dropout_rate_2': 0.3737800031887728}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  93%|█████████▎| 93/100 [1:23:48<05:49, 49.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:39:59,104] Trial 92 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 0.001152955700209297, 'weight_decay': 0.002318260933956039, 'batch_size': 32, 'hidden_size_0': 96, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.39305419782766543, 'dropout_rate_1': 0.41756314853299586, 'dropout_rate_2': 0.45752989770383584}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  94%|█████████▍| 94/100 [1:24:33<04:51, 48.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:40:44,258] Trial 93 finished with value: 0.22507910649978255 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0014137844375151085, 'weight_decay': 0.0014390256587448877, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.29005993908463645, 'dropout_rate_1': 0.34366360434419907, 'dropout_rate_2': 0.3293818571647222}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  95%|█████████▌| 95/100 [1:25:01<03:32, 42.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:41:12,492] Trial 94 finished with value: 0.22557314240072962 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0017663896393539415, 'weight_decay': 7.433282248645998e-05, 'batch_size': 48, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.53178477774349, 'dropout_rate_1': 0.4146125831431848, 'dropout_rate_2': 0.1303411729639129}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  96%|█████████▌| 96/100 [1:25:34<02:37, 39.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:41:44,899] Trial 95 finished with value: 0.22249560450498587 and parameters: {'use_batch_norm': True, 'learning_rate': 0.001945273465048428, 'weight_decay': 0.00012300865576558417, 'batch_size': 64, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.4709790480659192, 'dropout_rate_1': 0.38349920774738944, 'dropout_rate_2': 0.2898674435725632}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  97%|█████████▋| 97/100 [1:26:08<01:53, 37.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:42:19,257] Trial 96 finished with value: 0.2257115669244883 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0012898662422600059, 'weight_decay': 0.00012030302551961908, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.22101848355002857, 'dropout_rate_1': 0.41860116828443317, 'dropout_rate_2': 0.35153584965909385}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  98%|█████████▊| 98/100 [1:27:59<01:59, 59.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:44:10,416] Trial 97 finished with value: 0.22763592908655214 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0007876558269092243, 'weight_decay': 2.337116366526096e-05, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.3491493082326493, 'dropout_rate_1': 0.30339732200622066, 'dropout_rate_2': 0.16755239093053553}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 69. Best value: 0.218157:  99%|█████████▉| 99/100 [1:28:17<00:47, 47.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:44:28,343] Trial 98 finished with value: 0.22158491382591403 and parameters: {'use_batch_norm': False, 'learning_rate': 0.006655976054597098, 'weight_decay': 0.00040339298096726296, 'batch_size': 112, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.35232746887981947, 'dropout_rate_1': 0.4486093314806624, 'dropout_rate_2': 0.18453145845842836}. Best is trial 69 with value: 0.2181567822037072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 99. Best value: 0.218041: 100%|██████████| 100/100 [1:29:01<00:00, 53.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:45:12,431] Trial 99 finished with value: 0.21804061915059822 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0019261262846184653, 'weight_decay': 0.00011834720359209613, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.4653610767143221, 'dropout_rate_1': 0.38465019114405796, 'dropout_rate_2': 0.38654987245975936}. Best is trial 99 with value: 0.21804061915059822.\n",
      "\n",
      "================================================================================\n",
      "PSO Optimization Complete!\n",
      "Best validation loss: 0.2180\n",
      "Best trial: 99\n",
      "\n",
      "Best Hyperparameters:\n",
      "  Architecture: 3 layers with ReLU activation\n",
      "  Layer 1: 32 neurons, dropout=0.465\n",
      "  Layer 2: 32 neurons, dropout=0.385\n",
      "  Layer 3: 32 neurons, dropout=0.387\n",
      "  Learning rate: 0.001926\n",
      "  Weight decay: 0.000118\n",
      "  Batch size: 80\n",
      "  Batch normalization: False\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Starting training for 300 epochs with patience=50\n",
      "====================================================================================================\n",
      "Epoch   1/300 | Train: Loss 0.6208 Acc 66.06% F1 0.3732 AUROC 0.7156 | Val: Loss 0.4326 Acc 86.36% F1 0.8242 AUROC 0.9230\n",
      "Epoch  10/300 | Train: Loss 0.3346 Acc 89.29% F1 0.8668 AUROC 0.9221 | Val: Loss 0.2541 Acc 92.63% F1 0.9105 AUROC 0.9463\n",
      "Epoch  20/300 | Train: Loss 0.3103 Acc 90.50% F1 0.8838 AUROC 0.9231 | Val: Loss 0.2451 Acc 92.95% F1 0.9126 AUROC 0.9487\n",
      "Epoch  30/300 | Train: Loss 0.3027 Acc 90.42% F1 0.8816 AUROC 0.9257 | Val: Loss 0.2300 Acc 93.26% F1 0.9162 AUROC 0.9500\n",
      "Epoch  40/300 | Train: Loss 0.3052 Acc 90.64% F1 0.8846 AUROC 0.9230 | Val: Loss 0.2404 Acc 92.63% F1 0.9091 AUROC 0.9494\n",
      "Epoch  50/300 | Train: Loss 0.2986 Acc 90.61% F1 0.8843 AUROC 0.9251 | Val: Loss 0.2196 Acc 94.04% F1 0.9266 AUROC 0.9531\n",
      "Epoch  60/300 | Train: Loss 0.2942 Acc 90.92% F1 0.8880 AUROC 0.9269 | Val: Loss 0.2215 Acc 93.57% F1 0.9210 AUROC 0.9551\n",
      "Epoch  70/300 | Train: Loss 0.2969 Acc 90.92% F1 0.8881 AUROC 0.9242 | Val: Loss 0.2239 Acc 93.42% F1 0.9180 AUROC 0.9535\n",
      "Epoch  80/300 | Train: Loss 0.2977 Acc 91.31% F1 0.8932 AUROC 0.9211 | Val: Loss 0.2329 Acc 92.95% F1 0.9112 AUROC 0.9525\n",
      "Epoch  90/300 | Train: Loss 0.2875 Acc 91.00% F1 0.8886 AUROC 0.9332 | Val: Loss 0.2227 Acc 93.89% F1 0.9240 AUROC 0.9527\n",
      "Epoch 100/300 | Train: Loss 0.2916 Acc 91.17% F1 0.8905 AUROC 0.9272 | Val: Loss 0.2239 Acc 93.26% F1 0.9162 AUROC 0.9538\n",
      "Epoch 110/300 | Train: Loss 0.2911 Acc 91.06% F1 0.8894 AUROC 0.9282 | Val: Loss 0.2236 Acc 93.89% F1 0.9237 AUROC 0.9542\n",
      "Epoch 120/300 | Train: Loss 0.2869 Acc 91.22% F1 0.8917 AUROC 0.9308 | Val: Loss 0.2247 Acc 93.42% F1 0.9189 AUROC 0.9549\n",
      "====================================================================================================\n",
      "Early stopping at epoch 129\n",
      "====================================================================================================\n",
      "Training completed. Best model from epoch 79\n",
      "Best validation loss: 0.2186\n",
      "\n",
      "Final Model Performance:\n",
      "  Training Loss: 0.2913\n",
      "  Training Acc: 90.8361\n",
      "  Validation Loss: 0.2186\n",
      "  Validation Acc: 93.7304\n"
     ]
    }
   ],
   "source": [
    "from pso_hyperparameter_tuning import run_pso_hyperparameter_tuning\n",
    "\n",
    "# Your data (11 features, already scaled)\n",
    "pso_results = run_pso_hyperparameter_tuning(\n",
    "    X_train_scaled=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val_scaled=X_val,\n",
    "    y_val=y_val,\n",
    "    device=device,\n",
    "    n_trials=100,\n",
    "    n_particles=20,\n",
    "    epochs_per_trial=250,\n",
    "    patience=50,\n",
    "    inertia=0.7,\n",
    "    cognitive=1.4,\n",
    "    social=1.4,\n",
    "    verbose=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Get optimized model\n",
    "best_model = pso_results['final_model']\n",
    "best_params = pso_results['best_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efeeeea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'study': <optuna.study.study.Study at 0x1f1c5a7c830>,\n",
       " 'best_params': {'use_batch_norm': False,\n",
       "  'learning_rate': 0.0019261262846184653,\n",
       "  'weight_decay': 0.00011834720359209613,\n",
       "  'batch_size': 80,\n",
       "  'hidden_size_0': 32,\n",
       "  'hidden_size_1': 32,\n",
       "  'hidden_size_2': 32,\n",
       "  'dropout_rate_0': 0.4653610767143221,\n",
       "  'dropout_rate_1': 0.38465019114405796,\n",
       "  'dropout_rate_2': 0.38654987245975936},\n",
       " 'best_value': 0.21804061915059822,\n",
       " 'best_trial': FrozenTrial(number=99, state=1, values=[0.21804061915059822], datetime_start=datetime.datetime(2025, 10, 13, 20, 44, 28, 347763), datetime_complete=datetime.datetime(2025, 10, 13, 20, 45, 12, 431313), params={'use_batch_norm': False, 'learning_rate': 0.0019261262846184653, 'weight_decay': 0.00011834720359209613, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.4653610767143221, 'dropout_rate_1': 0.38465019114405796, 'dropout_rate_2': 0.38654987245975936}, user_attrs={}, system_attrs={}, intermediate_values={244: 0.21804061915059822}, distributions={'use_batch_norm': CategoricalDistribution(choices=(True, False)), 'learning_rate': FloatDistribution(high=0.01, log=True, low=1e-05, step=None), 'weight_decay': FloatDistribution(high=0.01, log=True, low=1e-06, step=None), 'batch_size': IntDistribution(high=128, log=False, low=16, step=16), 'hidden_size_0': IntDistribution(high=256, log=False, low=32, step=32), 'hidden_size_1': IntDistribution(high=32, log=False, low=16, step=16), 'hidden_size_2': IntDistribution(high=32, log=False, low=16, step=16), 'dropout_rate_0': FloatDistribution(high=0.6, log=False, low=0.1, step=None), 'dropout_rate_1': FloatDistribution(high=0.6, log=False, low=0.1, step=None), 'dropout_rate_2': FloatDistribution(high=0.6, log=False, low=0.1, step=None)}, trial_id=99, value=None),\n",
       " 'final_model': Sequential(\n",
       "   (0): Linear(in_features=11, out_features=32, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Dropout(p=0.4653610767143221, inplace=False)\n",
       "   (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "   (4): ReLU()\n",
       "   (5): Dropout(p=0.38465019114405796, inplace=False)\n",
       "   (6): Linear(in_features=32, out_features=32, bias=True)\n",
       "   (7): ReLU()\n",
       "   (8): Dropout(p=0.38654987245975936, inplace=False)\n",
       "   (9): Linear(in_features=32, out_features=2, bias=True)\n",
       " ),\n",
       " 'final_results': {'history': {'train_loss': [0.6208386492491561,\n",
       "    0.4625986999319505,\n",
       "    0.40418548448009217,\n",
       "    0.38613015551899754,\n",
       "    0.3686571624191893,\n",
       "    0.37037776336321404,\n",
       "    0.3535498655581659,\n",
       "    0.35814088474080413,\n",
       "    0.3453847279448314,\n",
       "    0.33455687045126925,\n",
       "    0.32954571156010676,\n",
       "    0.3305337441918066,\n",
       "    0.3250615581259511,\n",
       "    0.32357548825764576,\n",
       "    0.3293524593741923,\n",
       "    0.3261385568616662,\n",
       "    0.3178906866152289,\n",
       "    0.31723216172732654,\n",
       "    0.31913284279183296,\n",
       "    0.3103498310873807,\n",
       "    0.3137567332746711,\n",
       "    0.3065028860587482,\n",
       "    0.31405829148963177,\n",
       "    0.30693631313105885,\n",
       "    0.30384014730041603,\n",
       "    0.30710521502088206,\n",
       "    0.30537591391095553,\n",
       "    0.30446018814908576,\n",
       "    0.3021773509144915,\n",
       "    0.3027379279120816,\n",
       "    0.30805531866922725,\n",
       "    0.300590434228199,\n",
       "    0.30222939640481605,\n",
       "    0.3069011905660661,\n",
       "    0.30267485202282896,\n",
       "    0.3008973798482521,\n",
       "    0.30453607644617625,\n",
       "    0.29378683228099334,\n",
       "    0.30422268955579496,\n",
       "    0.30518210749425495,\n",
       "    0.29843708588963463,\n",
       "    0.2945992176978955,\n",
       "    0.2973296009622935,\n",
       "    0.2931002750085174,\n",
       "    0.30105895325458987,\n",
       "    0.29379413518662734,\n",
       "    0.29976620765223455,\n",
       "    0.29382773114993327,\n",
       "    0.30443099880403324,\n",
       "    0.29859859361865065,\n",
       "    0.2961714912622606,\n",
       "    0.2954422622126994,\n",
       "    0.2993085694603482,\n",
       "    0.29506857956399685,\n",
       "    0.29438016930819877,\n",
       "    0.30379655940720146,\n",
       "    0.2961880113199304,\n",
       "    0.2980445013159797,\n",
       "    0.29293525806429116,\n",
       "    0.2941598419434208,\n",
       "    0.2993079958233986,\n",
       "    0.29157498059742737,\n",
       "    0.2923668288313273,\n",
       "    0.2936035009515642,\n",
       "    0.2957944445237765,\n",
       "    0.2971796639271881,\n",
       "    0.2910279775510727,\n",
       "    0.2970024779901024,\n",
       "    0.29151925423975666,\n",
       "    0.29687297735301366,\n",
       "    0.2917277847941664,\n",
       "    0.28989845238716766,\n",
       "    0.28865367982326157,\n",
       "    0.29478952159088184,\n",
       "    0.29902741527504567,\n",
       "    0.29270621045087264,\n",
       "    0.28899403941195667,\n",
       "    0.2981864134652142,\n",
       "    0.29126569136960695,\n",
       "    0.29769801242010935,\n",
       "    0.2884164063851963,\n",
       "    0.28688415825564995,\n",
       "    0.29265444929549594,\n",
       "    0.29640588543871843,\n",
       "    0.2909969430280682,\n",
       "    0.28838170713364486,\n",
       "    0.29054420575879075,\n",
       "    0.28802097414683137,\n",
       "    0.28504846976081927,\n",
       "    0.2875398154868636,\n",
       "    0.2956372566463411,\n",
       "    0.2904967069873382,\n",
       "    0.2895332824517194,\n",
       "    0.2846936703982411,\n",
       "    0.28401184942602187,\n",
       "    0.2882134030889699,\n",
       "    0.2912977247407138,\n",
       "    0.29282786056052806,\n",
       "    0.2894969366053542,\n",
       "    0.2916049067826234,\n",
       "    0.290069772819612,\n",
       "    0.29820339215026215,\n",
       "    0.29157065563027645,\n",
       "    0.28924665838513,\n",
       "    0.2878552670296641,\n",
       "    0.28510701091978635,\n",
       "    0.2952762057185833,\n",
       "    0.29318131801825953,\n",
       "    0.2976357947090271,\n",
       "    0.2910757177031845,\n",
       "    0.2848589597878398,\n",
       "    0.2900501336172174,\n",
       "    0.2884778993272306,\n",
       "    0.29242039944642406,\n",
       "    0.2898574045726231,\n",
       "    0.2907027522821891,\n",
       "    0.28664981698409003,\n",
       "    0.2878783198933665,\n",
       "    0.2913449756462841,\n",
       "    0.2869077420907955,\n",
       "    0.2960391804031359,\n",
       "    0.2855600784733842,\n",
       "    0.28837842679895037,\n",
       "    0.2847065700183015,\n",
       "    0.28909994066091604,\n",
       "    0.2883057615751708,\n",
       "    0.2908749442097885,\n",
       "    0.2848902843059231,\n",
       "    0.2904987177777528],\n",
       "   'val_loss': [0.4326439816563107,\n",
       "    0.3244755456813824,\n",
       "    0.29069860508449397,\n",
       "    0.282848545843531,\n",
       "    0.2793758775933783,\n",
       "    0.27437686303566244,\n",
       "    0.266705920049763,\n",
       "    0.26528685645063094,\n",
       "    0.2673674906869667,\n",
       "    0.2541305776860647,\n",
       "    0.2525051180098124,\n",
       "    0.2507306746554599,\n",
       "    0.2507851859992574,\n",
       "    0.24892029675383553,\n",
       "    0.25502145267018705,\n",
       "    0.24477829543587556,\n",
       "    0.24319300415187045,\n",
       "    0.2436933637039041,\n",
       "    0.23613067424409442,\n",
       "    0.24513914634628356,\n",
       "    0.23756078081818582,\n",
       "    0.23554134509032795,\n",
       "    0.24237752040164973,\n",
       "    0.23603079292841467,\n",
       "    0.238814890805083,\n",
       "    0.23608594726432452,\n",
       "    0.23129072598529085,\n",
       "    0.23149985859760297,\n",
       "    0.2362230223454652,\n",
       "    0.22997052528454592,\n",
       "    0.23564291406761517,\n",
       "    0.23195453903704974,\n",
       "    0.23134019055336622,\n",
       "    0.23483080325829198,\n",
       "    0.23574002572922123,\n",
       "    0.22746498952838695,\n",
       "    0.2296537853613916,\n",
       "    0.22185286412418448,\n",
       "    0.2328660727761756,\n",
       "    0.2404472300998843,\n",
       "    0.2336420138894951,\n",
       "    0.23982874063488832,\n",
       "    0.23568416515301013,\n",
       "    0.23466229859190674,\n",
       "    0.22651500677614003,\n",
       "    0.22190757259306115,\n",
       "    0.22922437673078436,\n",
       "    0.2237236245672531,\n",
       "    0.22567120997883308,\n",
       "    0.2195959523273486,\n",
       "    0.23406816042702774,\n",
       "    0.2258114725538182,\n",
       "    0.22468146088541863,\n",
       "    0.22705592392567184,\n",
       "    0.22140695472309208,\n",
       "    0.22832267780475857,\n",
       "    0.22931948789982212,\n",
       "    0.22748190935315757,\n",
       "    0.22224711031188785,\n",
       "    0.22146440972355091,\n",
       "    0.23043934445022415,\n",
       "    0.2213861481242793,\n",
       "    0.22364957625963097,\n",
       "    0.2240156402408516,\n",
       "    0.22522266774341979,\n",
       "    0.23310701913407603,\n",
       "    0.2310365463218719,\n",
       "    0.22157988223162564,\n",
       "    0.2275908380092872,\n",
       "    0.22389726513605507,\n",
       "    0.22340085798856982,\n",
       "    0.22327142351286539,\n",
       "    0.22765660356017864,\n",
       "    0.22423272203875932,\n",
       "    0.22467237771678494,\n",
       "    0.23326839039505087,\n",
       "    0.22124316498964183,\n",
       "    0.22573969239912062,\n",
       "    0.21855661258988993,\n",
       "    0.23287135502761433,\n",
       "    0.219720780055351,\n",
       "    0.22267525215694522,\n",
       "    0.2326916029273903,\n",
       "    0.22700099091171097,\n",
       "    0.2229488919894897,\n",
       "    0.22606969673805477,\n",
       "    0.2295771295841211,\n",
       "    0.22396012281175692,\n",
       "    0.22119590999751254,\n",
       "    0.22269324748119965,\n",
       "    0.23204307351553327,\n",
       "    0.21899303938714687,\n",
       "    0.22302794222921413,\n",
       "    0.22078838640806445,\n",
       "    0.22521614238946788,\n",
       "    0.22235822644913833,\n",
       "    0.23552237072708465,\n",
       "    0.22394278094312614,\n",
       "    0.22151315361728488,\n",
       "    0.22387504395459512,\n",
       "    0.22228447555748274,\n",
       "    0.21876655243407223,\n",
       "    0.21951010823249817,\n",
       "    0.220256354321133,\n",
       "    0.22050063821215615,\n",
       "    0.22321798696787007,\n",
       "    0.22003509987110628,\n",
       "    0.2208460962230509,\n",
       "    0.2233689146636048,\n",
       "    0.22361312372183725,\n",
       "    0.2257745436459873,\n",
       "    0.22862353878895691,\n",
       "    0.2297240971210982,\n",
       "    0.22591440477715016,\n",
       "    0.21991330936410958,\n",
       "    0.22878128131355238,\n",
       "    0.22275940863690033,\n",
       "    0.22455733752923326,\n",
       "    0.22111928103298978,\n",
       "    0.22466117377191502,\n",
       "    0.22689472082827158,\n",
       "    0.22521085929721127,\n",
       "    0.22215963194736493,\n",
       "    0.22888303774651314,\n",
       "    0.22873220478292544,\n",
       "    0.2276997951598003,\n",
       "    0.22622098094056767,\n",
       "    0.22182532313475414,\n",
       "    0.22061876943305742],\n",
       "   'train_acc': [66.05758582502769,\n",
       "    80.98006644518273,\n",
       "    85.35437430786268,\n",
       "    86.7109634551495,\n",
       "    87.04318936877077,\n",
       "    87.95681063122923,\n",
       "    88.45514950166113,\n",
       "    88.12292358803987,\n",
       "    88.92580287929125,\n",
       "    89.28571428571429,\n",
       "    89.4795127353267,\n",
       "    89.25802879291251,\n",
       "    89.89479512735326,\n",
       "    89.92248062015504,\n",
       "    89.53488372093024,\n",
       "    89.64562569213732,\n",
       "    89.7563676633444,\n",
       "    90.14396456256921,\n",
       "    90.36544850498339,\n",
       "    90.50387596899225,\n",
       "    90.19933554817275,\n",
       "    90.17165005537099,\n",
       "    89.97785160575859,\n",
       "    90.53156146179403,\n",
       "    90.53156146179403,\n",
       "    90.4485049833887,\n",
       "    90.61461794019934,\n",
       "    90.31007751937985,\n",
       "    90.39313399778516,\n",
       "    90.42081949058694,\n",
       "    90.72535991140643,\n",
       "    90.8361018826135,\n",
       "    90.50387596899225,\n",
       "    90.50387596899225,\n",
       "    90.19933554817275,\n",
       "    90.61461794019934,\n",
       "    90.55924695459579,\n",
       "    90.78073089700996,\n",
       "    90.69767441860465,\n",
       "    90.6423034330011,\n",
       "    90.61461794019934,\n",
       "    90.80841638981174,\n",
       "    90.47619047619048,\n",
       "    91.11295681063123,\n",
       "    90.66998892580288,\n",
       "    90.50387596899225,\n",
       "    91.00221483942414,\n",
       "    91.08527131782945,\n",
       "    90.47619047619048,\n",
       "    90.61461794019934,\n",
       "    90.91915836101883,\n",
       "    90.66998892580288,\n",
       "    90.8361018826135,\n",
       "    90.66998892580288,\n",
       "    90.91915836101883,\n",
       "    90.31007751937985,\n",
       "    90.61461794019934,\n",
       "    91.08527131782945,\n",
       "    90.66998892580288,\n",
       "    90.91915836101883,\n",
       "    90.80841638981174,\n",
       "    90.9468438538206,\n",
       "    90.89147286821705,\n",
       "    90.86378737541528,\n",
       "    90.9468438538206,\n",
       "    90.78073089700996,\n",
       "    91.0299003322259,\n",
       "    90.69767441860465,\n",
       "    91.140642303433,\n",
       "    90.91915836101883,\n",
       "    90.89147286821705,\n",
       "    90.89147286821705,\n",
       "    91.00221483942414,\n",
       "    90.80841638981174,\n",
       "    90.42081949058694,\n",
       "    90.6423034330011,\n",
       "    90.91915836101883,\n",
       "    90.66998892580288,\n",
       "    90.8361018826135,\n",
       "    91.30675526024363,\n",
       "    90.7530454042082,\n",
       "    90.9468438538206,\n",
       "    91.00221483942414,\n",
       "    90.78073089700996,\n",
       "    91.11295681063123,\n",
       "    91.16832779623478,\n",
       "    91.22369878183832,\n",
       "    91.140642303433,\n",
       "    91.0299003322259,\n",
       "    91.00221483942414,\n",
       "    91.0299003322259,\n",
       "    91.05758582502769,\n",
       "    91.30675526024363,\n",
       "    91.16832779623478,\n",
       "    91.11295681063123,\n",
       "    91.38981173864894,\n",
       "    91.0299003322259,\n",
       "    90.7530454042082,\n",
       "    91.22369878183832,\n",
       "    91.16832779623478,\n",
       "    90.9468438538206,\n",
       "    90.55924695459579,\n",
       "    90.8361018826135,\n",
       "    91.25138427464009,\n",
       "    91.05758582502769,\n",
       "    91.00221483942414,\n",
       "    90.97452934662238,\n",
       "    91.30675526024363,\n",
       "    90.66998892580288,\n",
       "    91.05758582502769,\n",
       "    91.08527131782945,\n",
       "    91.11295681063123,\n",
       "    91.0299003322259,\n",
       "    91.30675526024363,\n",
       "    91.19601328903654,\n",
       "    91.08527131782945,\n",
       "    91.25138427464009,\n",
       "    91.11295681063123,\n",
       "    90.91915836101883,\n",
       "    91.22369878183832,\n",
       "    90.7530454042082,\n",
       "    91.22369878183832,\n",
       "    91.3344407530454,\n",
       "    91.36212624584718,\n",
       "    91.08527131782945,\n",
       "    91.08527131782945,\n",
       "    91.00221483942414,\n",
       "    91.22369878183832,\n",
       "    90.91915836101883],\n",
       "   'val_acc': [86.36363636363636,\n",
       "    90.12539184952978,\n",
       "    91.69278996865204,\n",
       "    91.53605015673982,\n",
       "    91.69278996865204,\n",
       "    91.84952978056427,\n",
       "    92.94670846394985,\n",
       "    92.94670846394985,\n",
       "    92.16300940438872,\n",
       "    92.6332288401254,\n",
       "    92.16300940438872,\n",
       "    93.41692789968653,\n",
       "    92.47648902821317,\n",
       "    93.10344827586206,\n",
       "    93.2601880877743,\n",
       "    92.94670846394985,\n",
       "    92.94670846394985,\n",
       "    93.10344827586206,\n",
       "    92.94670846394985,\n",
       "    92.94670846394985,\n",
       "    93.41692789968653,\n",
       "    93.10344827586206,\n",
       "    93.10344827586206,\n",
       "    93.41692789968653,\n",
       "    92.6332288401254,\n",
       "    92.47648902821317,\n",
       "    93.2601880877743,\n",
       "    92.78996865203762,\n",
       "    92.94670846394985,\n",
       "    93.2601880877743,\n",
       "    93.8871473354232,\n",
       "    93.41692789968653,\n",
       "    93.41692789968653,\n",
       "    93.57366771159874,\n",
       "    93.2601880877743,\n",
       "    93.8871473354232,\n",
       "    93.2601880877743,\n",
       "    93.2601880877743,\n",
       "    92.94670846394985,\n",
       "    92.6332288401254,\n",
       "    92.6332288401254,\n",
       "    92.6332288401254,\n",
       "    93.10344827586206,\n",
       "    92.94670846394985,\n",
       "    93.57366771159874,\n",
       "    93.8871473354232,\n",
       "    93.73040752351098,\n",
       "    93.73040752351098,\n",
       "    93.41692789968653,\n",
       "    94.04388714733543,\n",
       "    93.2601880877743,\n",
       "    93.8871473354232,\n",
       "    93.57366771159874,\n",
       "    93.73040752351098,\n",
       "    93.57366771159874,\n",
       "    93.41692789968653,\n",
       "    93.10344827586206,\n",
       "    93.57366771159874,\n",
       "    93.73040752351098,\n",
       "    93.57366771159874,\n",
       "    93.10344827586206,\n",
       "    94.20062695924764,\n",
       "    94.20062695924764,\n",
       "    93.57366771159874,\n",
       "    93.2601880877743,\n",
       "    93.2601880877743,\n",
       "    93.41692789968653,\n",
       "    93.8871473354232,\n",
       "    93.73040752351098,\n",
       "    93.41692789968653,\n",
       "    93.8871473354232,\n",
       "    93.41692789968653,\n",
       "    92.94670846394985,\n",
       "    93.2601880877743,\n",
       "    93.57366771159874,\n",
       "    92.6332288401254,\n",
       "    93.57366771159874,\n",
       "    93.41692789968653,\n",
       "    93.73040752351098,\n",
       "    92.94670846394985,\n",
       "    93.73040752351098,\n",
       "    93.73040752351098,\n",
       "    93.2601880877743,\n",
       "    93.41692789968653,\n",
       "    93.41692789968653,\n",
       "    93.57366771159874,\n",
       "    93.2601880877743,\n",
       "    93.73040752351098,\n",
       "    93.73040752351098,\n",
       "    93.8871473354232,\n",
       "    92.6332288401254,\n",
       "    93.8871473354232,\n",
       "    93.57366771159874,\n",
       "    93.57366771159874,\n",
       "    93.2601880877743,\n",
       "    93.57366771159874,\n",
       "    92.78996865203762,\n",
       "    93.73040752351098,\n",
       "    93.8871473354232,\n",
       "    93.2601880877743,\n",
       "    93.8871473354232,\n",
       "    93.73040752351098,\n",
       "    93.8871473354232,\n",
       "    93.73040752351098,\n",
       "    93.57366771159874,\n",
       "    93.73040752351098,\n",
       "    94.20062695924764,\n",
       "    93.8871473354232,\n",
       "    93.8871473354232,\n",
       "    93.8871473354232,\n",
       "    93.41692789968653,\n",
       "    93.57366771159874,\n",
       "    93.2601880877743,\n",
       "    93.41692789968653,\n",
       "    93.57366771159874,\n",
       "    93.10344827586206,\n",
       "    93.41692789968653,\n",
       "    93.2601880877743,\n",
       "    93.73040752351098,\n",
       "    93.41692789968653,\n",
       "    93.57366771159874,\n",
       "    93.41692789968653,\n",
       "    94.04388714733543,\n",
       "    93.57366771159874,\n",
       "    93.41692789968653,\n",
       "    93.57366771159874,\n",
       "    93.41692789968653,\n",
       "    94.04388714733543,\n",
       "    93.73040752351098]},\n",
       "  'best_train_metrics': {'loss': 0.29126569136960695,\n",
       "   'accuracy': 90.8361018826135,\n",
       "   'precision': 0.8931034482758621,\n",
       "   'recall': 0.8803535010197144,\n",
       "   'f1': 0.8866826429305033,\n",
       "   'auroc': 0.9294350594444486},\n",
       "  'best_val_metrics': {'loss': 0.21855661258988993,\n",
       "   'accuracy': 93.73040752351098,\n",
       "   'precision': 0.9296875,\n",
       "   'recall': 0.9153846153846154,\n",
       "   'f1': 0.9224806201550387,\n",
       "   'auroc': 0.9521774521774522},\n",
       "  'best_epoch': 79,\n",
       "  'total_epochs': 129,\n",
       "  'model': Sequential(\n",
       "    (0): Linear(in_features=11, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.4653610767143221, inplace=False)\n",
       "    (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.38465019114405796, inplace=False)\n",
       "    (6): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.38654987245975936, inplace=False)\n",
       "    (9): Linear(in_features=32, out_features=2, bias=True)\n",
       "  )},\n",
       " 'n_trials': 100,\n",
       " 'n_features': 11}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pso_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "219ac627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"pso_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pso_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4c5d16",
   "metadata": {},
   "source": [
    "### PSO 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74bf3078",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b8d57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:56:47,560] A new study created in memory with name: no-name-7fa3cb72-5254-4e2f-b31c-319a6551784b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PSO Hyperparameter Optimization\n",
      "Fixed Architecture: 3 hidden layers, ReLU activation, Adam optimizer\n",
      "Input features: 11\n",
      "Training samples: 3612\n",
      "Validation samples: 638\n",
      "PSO Settings: 25 particles, 100 trials\n",
      "PSO Coefficients: inertia=0.8, cognitive=1.4, social=1.7\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.222096:   1%|          | 1/100 [00:36<59:28, 36.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:57:23,606] Trial 0 finished with value: 0.2220956461977062 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0009454306819536165, 'weight_decay': 0.0002481040974867811, 'batch_size': 48, 'hidden_size_0': 64, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.5330880728874676, 'dropout_rate_1': 0.40055750587160444, 'dropout_rate_2': 0.2416145155592091}. Best is trial 0 with value: 0.2220956461977062.\n",
      "Trial 0/100 | Best value: 0.2221 | Best trial: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.222096:   2%|▏         | 2/100 [00:56<43:33, 26.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:57:43,703] Trial 1 finished with value: 0.2243831242933916 and parameters: {'use_batch_norm': False, 'learning_rate': 0.001764971584817572, 'weight_decay': 7.068974950624607e-06, 'batch_size': 48, 'hidden_size_0': 64, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.3159725093210579, 'dropout_rate_1': 0.24561457009902096, 'dropout_rate_2': 0.22237057894447587}. Best is trial 0 with value: 0.2220956461977062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.222096:   3%|▎         | 3/100 [01:29<47:59, 29.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:58:16,984] Trial 2 finished with value: 0.2382320460854653 and parameters: {'use_batch_norm': False, 'learning_rate': 9.745399020374078e-05, 'weight_decay': 6.672367170464208e-05, 'batch_size': 112, 'hidden_size_0': 64, 'hidden_size_1': 48, 'hidden_size_2': 32, 'dropout_rate_0': 0.12322520635999887, 'dropout_rate_1': 0.40377242595071916, 'dropout_rate_2': 0.1341048247374583}. Best is trial 0 with value: 0.2220956461977062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.222096:   4%|▍         | 4/100 [01:51<42:42, 26.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:58:39,102] Trial 3 finished with value: 0.22571065610852734 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00403842379807156, 'weight_decay': 0.0017123375973163992, 'batch_size': 64, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.16101911742238942, 'dropout_rate_1': 0.34758845505563507, 'dropout_rate_2': 0.10687770422304368}. Best is trial 0 with value: 0.2220956461977062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.222096:   5%|▌         | 5/100 [02:38<53:49, 34.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 20:59:26,040] Trial 4 finished with value: 0.2263858775173235 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0006139426050898153, 'weight_decay': 1.7654048052495086e-05, 'batch_size': 80, 'hidden_size_0': 160, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.48756641168055725, 'dropout_rate_1': 0.5697494707820946, 'dropout_rate_2': 0.27896547008552974}. Best is trial 0 with value: 0.2220956461977062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.222096:   6%|▌         | 6/100 [03:57<1:17:13, 49.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:00:45,022] Trial 5 finished with value: 0.26718104343429255 and parameters: {'use_batch_norm': False, 'learning_rate': 1.7331598058558698e-05, 'weight_decay': 6.0803901902966035e-06, 'batch_size': 32, 'hidden_size_0': 96, 'hidden_size_1': 48, 'hidden_size_2': 16, 'dropout_rate_0': 0.5143687545759646, 'dropout_rate_1': 0.2783766633467947, 'dropout_rate_2': 0.15618690193747614}. Best is trial 0 with value: 0.2220956461977062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.222096:   7%|▋         | 7/100 [04:11<58:30, 37.75s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:00:59,006] Trial 6 finished with value: 0.22752107492995485 and parameters: {'use_batch_norm': True, 'learning_rate': 0.001462532712120769, 'weight_decay': 1.987021538542864e-06, 'batch_size': 128, 'hidden_size_0': 224, 'hidden_size_1': 48, 'hidden_size_2': 16, 'dropout_rate_0': 0.5077307142274171, 'dropout_rate_1': 0.45342867192380854, 'dropout_rate_2': 0.24580143360819745}. Best is trial 0 with value: 0.2220956461977062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.222096:   8%|▊         | 8/100 [04:38<52:29, 34.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:01:25,716] Trial 7 finished with value: 0.2370989339478711 and parameters: {'use_batch_norm': True, 'learning_rate': 9.278723835524691e-05, 'weight_decay': 2.907208890659845e-06, 'batch_size': 128, 'hidden_size_0': 160, 'hidden_size_1': 64, 'hidden_size_2': 16, 'dropout_rate_0': 0.2554911608578311, 'dropout_rate_1': 0.2625916610133735, 'dropout_rate_2': 0.24592123566761281}. Best is trial 0 with value: 0.2220956461977062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.222096:   9%|▉         | 9/100 [04:55<44:02, 29.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:01:43,305] Trial 8 finished with value: 0.23127347226240044 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00018814553601769867, 'weight_decay': 3.0086868214458464e-06, 'batch_size': 96, 'hidden_size_0': 224, 'hidden_size_1': 112, 'hidden_size_2': 96, 'dropout_rate_0': 0.34689779818219535, 'dropout_rate_1': 0.36136641469099706, 'dropout_rate_2': 0.18550820367170992}. Best is trial 0 with value: 0.2220956461977062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.222096:  10%|█         | 10/100 [05:41<51:06, 34.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:02:28,684] Trial 9 finished with value: 0.26580660998073863 and parameters: {'use_batch_norm': False, 'learning_rate': 1.2157000356394407e-05, 'weight_decay': 0.00035127047262708476, 'batch_size': 64, 'hidden_size_0': 160, 'hidden_size_1': 160, 'hidden_size_2': 32, 'dropout_rate_0': 0.30519146151781484, 'dropout_rate_1': 0.4777755692715243, 'dropout_rate_2': 0.1457596330983245}. Best is trial 0 with value: 0.2220956461977062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.222096:  11%|█         | 11/100 [06:13<49:35, 33.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:03:00,656] Trial 10 finished with value: 0.2543970772932316 and parameters: {'use_batch_norm': False, 'learning_rate': 2.723525327483574e-05, 'weight_decay': 0.005233480488540089, 'batch_size': 112, 'hidden_size_0': 192, 'hidden_size_1': 176, 'hidden_size_2': 112, 'dropout_rate_0': 0.19328502944301792, 'dropout_rate_1': 0.5462794992449889, 'dropout_rate_2': 0.20786844838313012}. Best is trial 0 with value: 0.2220956461977062.\n",
      "Trial 10/100 | Best value: 0.2221 | Best trial: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.222096:  12%|█▏        | 12/100 [07:07<58:21, 39.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:03:54,983] Trial 11 finished with value: 0.23568493917257435 and parameters: {'use_batch_norm': False, 'learning_rate': 7.215756017643583e-05, 'weight_decay': 2.7555462077796614e-06, 'batch_size': 48, 'hidden_size_0': 128, 'hidden_size_1': 112, 'hidden_size_2': 112, 'dropout_rate_0': 0.10347606526559536, 'dropout_rate_1': 0.35537365128878284, 'dropout_rate_2': 0.1834822006297558}. Best is trial 0 with value: 0.2220956461977062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.222096:  13%|█▎        | 13/100 [08:09<1:07:34, 46.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:04:57,275] Trial 12 finished with value: 0.23151826624959987 and parameters: {'use_batch_norm': True, 'learning_rate': 8.151043683305622e-05, 'weight_decay': 0.005910698619088547, 'batch_size': 64, 'hidden_size_0': 160, 'hidden_size_1': 128, 'hidden_size_2': 48, 'dropout_rate_0': 0.5858910413604803, 'dropout_rate_1': 0.5812236474710556, 'dropout_rate_2': 0.15035645916507284}. Best is trial 0 with value: 0.2220956461977062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.222096:  14%|█▍        | 14/100 [08:57<1:07:05, 46.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:05:44,564] Trial 13 finished with value: 0.2470852996114653 and parameters: {'use_batch_norm': True, 'learning_rate': 5.871863488183303e-05, 'weight_decay': 1.4045842344024705e-06, 'batch_size': 96, 'hidden_size_0': 160, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.23932323211830572, 'dropout_rate_1': 0.5541329429833268, 'dropout_rate_2': 0.14791237813339447}. Best is trial 0 with value: 0.2220956461977062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.222096:  15%|█▌        | 15/100 [09:07<50:53, 35.93s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:05:55,266] Trial 14 finished with value: 0.2284097711447638 and parameters: {'use_batch_norm': False, 'learning_rate': 0.004573419197153427, 'weight_decay': 9.294394155644998e-06, 'batch_size': 96, 'hidden_size_0': 224, 'hidden_size_1': 48, 'hidden_size_2': 48, 'dropout_rate_0': 0.28389156635962665, 'dropout_rate_1': 0.41615291529678977, 'dropout_rate_2': 0.22670594215217893}. Best is trial 0 with value: 0.2220956461977062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.222096:  16%|█▌        | 16/100 [09:35<46:40, 33.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:06:22,614] Trial 15 finished with value: 0.23051063798157773 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0017966206213495693, 'weight_decay': 1.91920011015619e-05, 'batch_size': 48, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.10829391446392808, 'dropout_rate_1': 0.3560465291496405, 'dropout_rate_2': 0.1452991550395876}. Best is trial 0 with value: 0.2220956461977062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.222096:  17%|█▋        | 17/100 [10:02<43:52, 31.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:06:50,556] Trial 16 finished with value: 0.2229094050801286 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0007325212536639256, 'weight_decay': 3.523233163198316e-05, 'batch_size': 128, 'hidden_size_0': 64, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.5623468091392814, 'dropout_rate_1': 0.5386696766904905, 'dropout_rate_2': 0.15158832554303112}. Best is trial 0 with value: 0.2220956461977062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.221821:  18%|█▊        | 18/100 [10:59<53:19, 39.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:07:46,578] Trial 17 finished with value: 0.22182097185554922 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0003151159142902247, 'weight_decay': 0.0001314021022620739, 'batch_size': 48, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.416550728636634, 'dropout_rate_1': 0.2695148955243504, 'dropout_rate_2': 0.16984191492253217}. Best is trial 17 with value: 0.22182097185554922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.221821:  19%|█▉        | 19/100 [11:11<42:07, 31.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:07:59,556] Trial 18 finished with value: 0.22411831671541388 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0024786753644700068, 'weight_decay': 0.0013167465326936148, 'batch_size': 96, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.5492770942635397, 'dropout_rate_1': 0.403214529829795, 'dropout_rate_2': 0.10183941032332594}. Best is trial 17 with value: 0.22182097185554922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.221821:  20%|██        | 20/100 [11:47<43:26, 32.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:08:35,336] Trial 19 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 1.0319557208250053e-05, 'weight_decay': 4.3977668944839625e-06, 'batch_size': 80, 'hidden_size_0': 192, 'hidden_size_1': 128, 'hidden_size_2': 32, 'dropout_rate_0': 0.45608961067376796, 'dropout_rate_1': 0.21862454374840004, 'dropout_rate_2': 0.16507993963185355}. Best is trial 17 with value: 0.22182097185554922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.221821:  21%|██        | 21/100 [12:00<35:06, 26.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:08:48,218] Trial 20 finished with value: 0.22825176911107425 and parameters: {'use_batch_norm': True, 'learning_rate': 0.001958973278004597, 'weight_decay': 0.00042702329684055453, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.23260118384086273, 'dropout_rate_1': 0.2219948216895418, 'dropout_rate_2': 0.2946021109504891}. Best is trial 17 with value: 0.22182097185554922.\n",
      "Trial 20/100 | Best value: 0.2218 | Best trial: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.221821:  22%|██▏       | 22/100 [12:30<35:54, 27.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:09:18,090] Trial 21 finished with value: 0.22686264661599104 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0005051544930614767, 'weight_decay': 0.0015109330261674466, 'batch_size': 80, 'hidden_size_0': 160, 'hidden_size_1': 80, 'hidden_size_2': 16, 'dropout_rate_0': 0.46122605763075264, 'dropout_rate_1': 0.2403861812204279, 'dropout_rate_2': 0.10486319328629078}. Best is trial 17 with value: 0.22182097185554922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.221821:  23%|██▎       | 23/100 [12:41<29:11, 22.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:09:29,473] Trial 22 finished with value: 0.22904748331790434 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0034535799115139056, 'weight_decay': 0.006542056762893132, 'batch_size': 128, 'hidden_size_0': 96, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.5641592812938627, 'dropout_rate_1': 0.31409207415865714, 'dropout_rate_2': 0.2933309638087339}. Best is trial 17 with value: 0.22182097185554922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.221821:  24%|██▍       | 24/100 [13:17<33:39, 26.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:10:04,941] Trial 23 finished with value: 0.24470117071579242 and parameters: {'use_batch_norm': True, 'learning_rate': 6.233166494382179e-05, 'weight_decay': 3.470490935437502e-05, 'batch_size': 112, 'hidden_size_0': 96, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.5680773870803905, 'dropout_rate_1': 0.44801489833748653, 'dropout_rate_2': 0.214012234017873}. Best is trial 17 with value: 0.22182097185554922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.221821:  25%|██▌       | 25/100 [13:30<28:13, 22.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:10:18,201] Trial 24 finished with value: 0.23470193647478815 and parameters: {'use_batch_norm': False, 'learning_rate': 0.004700300715751031, 'weight_decay': 3.6335911653931684e-06, 'batch_size': 80, 'hidden_size_0': 256, 'hidden_size_1': 144, 'hidden_size_2': 96, 'dropout_rate_0': 0.45124204199355467, 'dropout_rate_1': 0.27974557560987756, 'dropout_rate_2': 0.15871836885289867}. Best is trial 17 with value: 0.22182097185554922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.221821:  26%|██▌       | 26/100 [14:09<33:56, 27.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:10:57,261] Trial 25 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 1e-05, 'weight_decay': 0.007315482131536127, 'batch_size': 96, 'hidden_size_0': 96, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.1, 'dropout_rate_1': 0.4809894281056096, 'dropout_rate_2': 0.21088079087656048}. Best is trial 17 with value: 0.22182097185554922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.221821:  27%|██▋       | 27/100 [14:20<27:22, 22.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:11:08,033] Trial 26 finished with value: 0.2312529357529733 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0029929606080023353, 'weight_decay': 1e-06, 'batch_size': 128, 'hidden_size_0': 160, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.1601668707643265, 'dropout_rate_1': 0.1, 'dropout_rate_2': 0.18725636068027446}. Best is trial 17 with value: 0.22182097185554922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.221821:  28%|██▊       | 28/100 [16:11<58:52, 49.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:12:59,086] Trial 27 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 1e-05, 'weight_decay': 1e-06, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.48615378924592123, 'dropout_rate_1': 0.4835668563039853, 'dropout_rate_2': 0.1}. Best is trial 17 with value: 0.22182097185554922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.221821:  29%|██▉       | 29/100 [16:43<51:53, 43.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:13:30,795] Trial 28 finished with value: 0.22436144326734692 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0024522488464424393, 'weight_decay': 0.0016029050712021088, 'batch_size': 96, 'hidden_size_0': 64, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.5753231090084509, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.2591585338872202}. Best is trial 17 with value: 0.22182097185554922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.221821:  30%|███       | 30/100 [17:36<54:25, 46.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:14:23,958] Trial 29 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 1e-05, 'weight_decay': 1e-06, 'batch_size': 64, 'hidden_size_0': 64, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.112016717961888, 'dropout_rate_1': 0.4058712180093953, 'dropout_rate_2': 0.1}. Best is trial 17 with value: 0.22182097185554922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.221821:  31%|███       | 31/100 [17:59<45:29, 39.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:14:46,972] Trial 30 finished with value: 0.22212147523523498 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0030984724291552067, 'weight_decay': 1e-06, 'batch_size': 48, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.2156560281992348}. Best is trial 17 with value: 0.22182097185554922.\n",
      "Trial 30/100 | Best value: 0.2218 | Best trial: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.221821:  32%|███▏      | 32/100 [18:17<37:32, 33.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:15:05,085] Trial 31 finished with value: 0.2361878121160788 and parameters: {'use_batch_norm': False, 'learning_rate': 0.002689516924021454, 'weight_decay': 0.006846749591686265, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.36060535221259843, 'dropout_rate_1': 0.1, 'dropout_rate_2': 0.15730825042565688}. Best is trial 17 with value: 0.22182097185554922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.221821:  33%|███▎      | 33/100 [18:59<39:53, 35.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:15:46,890] Trial 32 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 1e-05, 'weight_decay': 1e-06, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.49104299962587244, 'dropout_rate_2': 0.1}. Best is trial 17 with value: 0.22182097185554922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.221821:  34%|███▍      | 34/100 [19:26<36:34, 33.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:16:14,345] Trial 33 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 1e-05, 'weight_decay': 0.005111406909038654, 'batch_size': 128, 'hidden_size_0': 64, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.3207101299159577, 'dropout_rate_1': 0.1, 'dropout_rate_2': 0.20444865201096085}. Best is trial 17 with value: 0.22182097185554922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  35%|███▌      | 35/100 [19:45<31:09, 28.76s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:16:32,630] Trial 34 finished with value: 0.22146023387165278 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0024250627110771064, 'weight_decay': 1e-06, 'batch_size': 96, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.51088714624191, 'dropout_rate_1': 0.4949441625171188, 'dropout_rate_2': 0.13663436520044944}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  36%|███▌      | 36/100 [20:10<29:33, 27.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:16:57,895] Trial 35 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 1e-05, 'weight_decay': 0.004755448743763581, 'batch_size': 128, 'hidden_size_0': 128, 'hidden_size_1': 80, 'hidden_size_2': 16, 'dropout_rate_0': 0.5119164556782047, 'dropout_rate_1': 0.11679711488385447, 'dropout_rate_2': 0.1}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  37%|███▋      | 37/100 [20:43<30:53, 29.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:17:31,320] Trial 36 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 1e-05, 'weight_decay': 1e-06, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.2787909793779308, 'dropout_rate_1': 0.27180633106621227, 'dropout_rate_2': 0.20326006966023907}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  38%|███▊      | 38/100 [21:32<36:32, 35.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:18:20,541] Trial 37 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 1e-05, 'weight_decay': 1e-06, 'batch_size': 48, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.1156912762684532}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  39%|███▉      | 39/100 [22:02<34:07, 33.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:18:49,915] Trial 38 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 1e-05, 'weight_decay': 0.0064945885827169675, 'batch_size': 96, 'hidden_size_0': 64, 'hidden_size_1': 64, 'hidden_size_2': 16, 'dropout_rate_0': 0.1, 'dropout_rate_1': 0.1, 'dropout_rate_2': 0.1}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  40%|████      | 40/100 [23:07<43:00, 43.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:19:54,953] Trial 39 finished with value: 0.25175362120040906 and parameters: {'use_batch_norm': True, 'learning_rate': 2.9357304117425833e-05, 'weight_decay': 0.005838729768267675, 'batch_size': 48, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.1, 'dropout_rate_1': 0.239349338043074, 'dropout_rate_2': 0.15004857963291907}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  41%|████      | 41/100 [23:41<39:34, 40.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:20:28,740] Trial 40 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 1e-05, 'weight_decay': 0.0003508322314649455, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.23117175503351708, 'dropout_rate_1': 0.29232020345307996, 'dropout_rate_2': 0.1}. Best is trial 34 with value: 0.22146023387165278.\n",
      "Trial 40/100 | Best value: 0.2215 | Best trial: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  42%|████▏     | 42/100 [25:20<55:53, 57.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:22:07,573] Trial 41 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 1e-05, 'weight_decay': 1e-06, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.1, 'dropout_rate_2': 0.1}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  43%|████▎     | 43/100 [26:13<53:42, 56.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:23:01,106] Trial 42 finished with value: 0.24612675831422537 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00014652883456679205, 'weight_decay': 0.007901032327305109, 'batch_size': 64, 'hidden_size_0': 96, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.5991238075261217, 'dropout_rate_1': 0.16374140169975293, 'dropout_rate_2': 0.27568657939739577}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  44%|████▍     | 44/100 [26:43<45:24, 48.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:23:31,362] Trial 43 finished with value: 0.22991753488685643 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0018355808735898232, 'weight_decay': 0.0006391074362666914, 'batch_size': 32, 'hidden_size_0': 160, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.102792446232856, 'dropout_rate_1': 0.34184686007566545, 'dropout_rate_2': 0.28923598151469176}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  45%|████▌     | 45/100 [28:36<1:02:08, 67.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:25:23,844] Trial 44 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 1e-05, 'weight_decay': 0.0003979244481285987, 'batch_size': 32, 'hidden_size_0': 160, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.33236602091103673, 'dropout_rate_1': 0.5964500193983381, 'dropout_rate_2': 0.1}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  46%|████▌     | 46/100 [29:16<53:41, 59.65s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:26:04,470] Trial 45 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 1e-05, 'weight_decay': 1e-06, 'batch_size': 112, 'hidden_size_0': 160, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.5392073415205237, 'dropout_rate_1': 0.2886611478858988, 'dropout_rate_2': 0.2807800070157644}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  47%|████▋     | 47/100 [29:59<48:17, 54.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:26:47,519] Trial 46 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 1e-05, 'weight_decay': 1e-06, 'batch_size': 96, 'hidden_size_0': 96, 'hidden_size_1': 48, 'hidden_size_2': 16, 'dropout_rate_0': 0.2793642947234827, 'dropout_rate_1': 0.4582036569853754, 'dropout_rate_2': 0.19469435415611314}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  48%|████▊     | 48/100 [30:41<43:57, 50.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:27:29,018] Trial 47 finished with value: 0.23698695088068145 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00011900146960290865, 'weight_decay': 0.0012635524891197415, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.5156504605246863, 'dropout_rate_1': 0.1, 'dropout_rate_2': 0.1}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  49%|████▉     | 49/100 [31:15<38:43, 45.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:28:02,571] Trial 48 finished with value: 0.23249639652459225 and parameters: {'use_batch_norm': False, 'learning_rate': 0.003014877042934103, 'weight_decay': 1e-06, 'batch_size': 48, 'hidden_size_0': 64, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.23629935598543472, 'dropout_rate_1': 0.5790440319220701, 'dropout_rate_2': 0.1}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  50%|█████     | 50/100 [31:57<37:07, 44.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:28:44,710] Trial 49 finished with value: 0.2433921507907138 and parameters: {'use_batch_norm': False, 'learning_rate': 7.592033419569731e-05, 'weight_decay': 0.0039820027205035744, 'batch_size': 96, 'hidden_size_0': 256, 'hidden_size_1': 160, 'hidden_size_2': 16, 'dropout_rate_0': 0.12145005243469786, 'dropout_rate_1': 0.16479583406997977, 'dropout_rate_2': 0.1}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  51%|█████     | 51/100 [32:31<33:56, 41.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:29:19,328] Trial 50 finished with value: 0.23401889564662143 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0005995071316732543, 'weight_decay': 0.004937699977007833, 'batch_size': 96, 'hidden_size_0': 64, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.48246507786460235, 'dropout_rate_1': 0.5361848711639932, 'dropout_rate_2': 0.15099363078453903}. Best is trial 34 with value: 0.22146023387165278.\n",
      "Trial 50/100 | Best value: 0.2215 | Best trial: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  52%|█████▏    | 52/100 [33:05<31:23, 39.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:29:53,180] Trial 51 finished with value: 0.22197261821700487 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0032336380749637067, 'weight_decay': 1.975718537852092e-06, 'batch_size': 64, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.29229542604269537, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.1}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  53%|█████▎    | 53/100 [33:44<30:37, 39.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:30:31,909] Trial 52 finished with value: 0.2227788709547826 and parameters: {'use_batch_norm': True, 'learning_rate': 0.00393538415927855, 'weight_decay': 4.43912060399958e-05, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.2920434349174603, 'dropout_rate_1': 0.5488984835252213, 'dropout_rate_2': 0.14745358109830936}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  54%|█████▍    | 54/100 [34:02<25:09, 32.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:30:50,067] Trial 53 finished with value: 0.225850536905486 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0011630136373234862, 'weight_decay': 0.0004888494221135303, 'batch_size': 96, 'hidden_size_0': 64, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.43934054770476905, 'dropout_rate_2': 0.1776339852413044}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 0.22146:  55%|█████▌    | 55/100 [34:23<21:54, 29.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:31:10,885] Trial 54 finished with value: 0.22656535513722412 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0030153594280194936, 'weight_decay': 2.2135002131950307e-05, 'batch_size': 112, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.15615559275497784, 'dropout_rate_1': 0.41937307291017706, 'dropout_rate_2': 0.20912335786318698}. Best is trial 34 with value: 0.22146023387165278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 55. Best value: 0.22053:  56%|█████▌    | 56/100 [34:56<22:19, 30.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:31:44,173] Trial 55 finished with value: 0.22052969585018098 and parameters: {'use_batch_norm': True, 'learning_rate': 0.004650644133291731, 'weight_decay': 1e-06, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.49487246537933377, 'dropout_rate_1': 0.5030721694388692, 'dropout_rate_2': 0.29223811276478284}. Best is trial 55 with value: 0.22052969585018098.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 55. Best value: 0.22053:  57%|█████▋    | 57/100 [35:09<17:57, 25.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:31:56,709] Trial 56 finished with value: 0.22741146801407433 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0028498418898365786, 'weight_decay': 0.0034664027007484037, 'batch_size': 128, 'hidden_size_0': 192, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.1138722601750331}. Best is trial 55 with value: 0.22052969585018098.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 55. Best value: 0.22053:  58%|█████▊    | 58/100 [35:21<14:51, 21.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:32:09,011] Trial 57 finished with value: 0.22954591678975145 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0040710501356547996, 'weight_decay': 2.538743197731501e-06, 'batch_size': 80, 'hidden_size_0': 96, 'hidden_size_1': 96, 'hidden_size_2': 16, 'dropout_rate_0': 0.1, 'dropout_rate_1': 0.5322574461819202, 'dropout_rate_2': 0.1265438381916247}. Best is trial 55 with value: 0.22052969585018098.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 55. Best value: 0.22053:  59%|█████▉    | 59/100 [35:36<13:13, 19.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:32:23,957] Trial 58 finished with value: 0.22298395748142164 and parameters: {'use_batch_norm': False, 'learning_rate': 0.003121489447459082, 'weight_decay': 1e-06, 'batch_size': 128, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.49460718182202934, 'dropout_rate_1': 0.5080011684858854, 'dropout_rate_2': 0.16379512605875227}. Best is trial 55 with value: 0.22052969585018098.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  60%|██████    | 60/100 [35:53<12:30, 18.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:32:41,321] Trial 59 finished with value: 0.21596265567881187 and parameters: {'use_batch_norm': True, 'learning_rate': 0.004355387279653677, 'weight_decay': 1e-06, 'batch_size': 96, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.5086790371135944, 'dropout_rate_2': 0.1293341508821494}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  61%|██████    | 61/100 [36:12<12:10, 18.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:33:00,032] Trial 60 finished with value: 0.2247885150782367 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0016599766429319662, 'weight_decay': 1e-06, 'batch_size': 128, 'hidden_size_0': 96, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.5639634752259683, 'dropout_rate_1': 0.2625623518640036, 'dropout_rate_2': 0.20666942563933732}. Best is trial 59 with value: 0.21596265567881187.\n",
      "Trial 60/100 | Best value: 0.2160 | Best trial: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  62%|██████▏   | 62/100 [36:39<13:21, 21.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:33:26,618] Trial 61 finished with value: 0.23668252375432317 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00012649200043860574, 'weight_decay': 1.0623936885724098e-06, 'batch_size': 112, 'hidden_size_0': 128, 'hidden_size_1': 80, 'hidden_size_2': 16, 'dropout_rate_0': 0.403797810309354, 'dropout_rate_1': 0.32423045314566534, 'dropout_rate_2': 0.26482831912920846}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  63%|██████▎   | 63/100 [36:58<12:39, 20.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:33:45,782] Trial 62 finished with value: 0.23852551347783366 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0009491669025357714, 'weight_decay': 0.006869888862040002, 'batch_size': 64, 'hidden_size_0': 160, 'hidden_size_1': 48, 'hidden_size_2': 48, 'dropout_rate_0': 0.45845905043953894, 'dropout_rate_1': 0.5386113759678898, 'dropout_rate_2': 0.2606961860769697}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  64%|██████▍   | 64/100 [37:18<12:16, 20.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:34:06,095] Trial 63 finished with value: 0.22333698126496193 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0031709623291652873, 'weight_decay': 0.0047763611949748225, 'batch_size': 96, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.4820826784836435, 'dropout_rate_1': 0.3023032504506355, 'dropout_rate_2': 0.1803525165372159}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  65%|██████▌   | 65/100 [37:49<13:49, 23.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:34:37,370] Trial 64 finished with value: 0.23468878047780184 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00012991004501022518, 'weight_decay': 1e-06, 'batch_size': 80, 'hidden_size_0': 64, 'hidden_size_1': 48, 'hidden_size_2': 32, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.5009335010212252, 'dropout_rate_2': 0.2552825921483993}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  66%|██████▌   | 66/100 [38:06<12:12, 21.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:34:53,848] Trial 65 finished with value: 0.22139935419664114 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0017568105585026507, 'weight_decay': 0.00032473077040429533, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.25444055387759207, 'dropout_rate_1': 0.4647474331774043, 'dropout_rate_2': 0.17327087901754812}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  67%|██████▋   | 67/100 [38:50<15:36, 28.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:35:38,201] Trial 66 finished with value: 0.22583995603001603 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0034114369408965155, 'weight_decay': 1.483572363209547e-05, 'batch_size': 32, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.49970981492994293, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.18847745029470309}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  68%|██████▊   | 68/100 [39:10<13:48, 25.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:35:58,309] Trial 67 finished with value: 0.227168996739537 and parameters: {'use_batch_norm': True, 'learning_rate': 0.003290154817608626, 'weight_decay': 0.003627404112455556, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.4964402299217202, 'dropout_rate_1': 0.19264553625347466, 'dropout_rate_2': 0.1}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  69%|██████▉   | 69/100 [39:21<11:05, 21.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:36:09,408] Trial 68 finished with value: 0.2224637881902318 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0019728557648326806, 'weight_decay': 1e-06, 'batch_size': 112, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.5930396202223731, 'dropout_rate_2': 0.16951699153825583}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  70%|███████   | 70/100 [39:59<13:12, 26.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:36:47,429] Trial 69 finished with value: 0.22107892794108316 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0035494620923852303, 'weight_decay': 1e-06, 'batch_size': 64, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.47139152784233146, 'dropout_rate_1': 0.3784302737839276, 'dropout_rate_2': 0.14799908950579632}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  71%|███████   | 71/100 [40:16<11:24, 23.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:37:04,485] Trial 70 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 0.003678410346475642, 'weight_decay': 0.00020371251360924974, 'batch_size': 112, 'hidden_size_0': 256, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.40296351205323716, 'dropout_rate_1': 0.49773239631986255, 'dropout_rate_2': 0.1}. Best is trial 59 with value: 0.21596265567881187.\n",
      "Trial 70/100 | Best value: 0.2160 | Best trial: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  72%|███████▏  | 72/100 [40:33<10:02, 21.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:37:21,113] Trial 71 finished with value: 0.2242134056962022 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0037179579567971034, 'weight_decay': 0.00211053914000665, 'batch_size': 112, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.4332171604350735, 'dropout_rate_1': 0.38397525628845114, 'dropout_rate_2': 0.1586421543396129}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  73%|███████▎  | 73/100 [41:00<10:24, 23.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:37:48,018] Trial 72 finished with value: 0.22413222926163748 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0010730903440223946, 'weight_decay': 1e-06, 'batch_size': 64, 'hidden_size_0': 128, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.5180326663272709, 'dropout_rate_1': 0.2775644378818608, 'dropout_rate_2': 0.2583158087451697}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  74%|███████▍  | 74/100 [41:28<10:36, 24.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:38:15,662] Trial 73 finished with value: 0.22529261897910724 and parameters: {'use_batch_norm': True, 'learning_rate': 0.004595236183141461, 'weight_decay': 1e-06, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.4352991500093921, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.12467732720801378}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  75%|███████▌  | 75/100 [41:47<09:36, 23.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:38:35,372] Trial 74 finished with value: 0.22352640597050466 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0016507089444908912, 'weight_decay': 1e-06, 'batch_size': 112, 'hidden_size_0': 192, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.18849383810839254}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  76%|███████▌  | 76/100 [42:30<11:34, 28.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:39:17,986] Trial 75 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 2.069952434165229e-05, 'weight_decay': 0.0018254485412882901, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.5486887769866494, 'dropout_rate_2': 0.10605306662267575}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  77%|███████▋  | 77/100 [43:04<11:42, 30.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:39:52,343] Trial 76 finished with value: 0.22134044145155102 and parameters: {'use_batch_norm': False, 'learning_rate': 0.004756239746149303, 'weight_decay': 1.6281292372293242e-06, 'batch_size': 48, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.5954594869175038, 'dropout_rate_2': 0.14118187637552423}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  78%|███████▊  | 78/100 [43:38<11:34, 31.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:40:26,263] Trial 77 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 1.6865598092331173e-05, 'weight_decay': 6.726923127539758e-06, 'batch_size': 96, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.545024617071201, 'dropout_rate_1': 0.5938491917825599, 'dropout_rate_2': 0.1619744796246655}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  79%|███████▉  | 79/100 [43:56<09:37, 27.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:40:44,348] Trial 78 finished with value: 0.22499010291499405 and parameters: {'use_batch_norm': False, 'learning_rate': 0.002741913242394937, 'weight_decay': 0.0005122439723951027, 'batch_size': 96, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.5676209607008083, 'dropout_rate_1': 0.5682672441345221, 'dropout_rate_2': 0.2521226219669709}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  80%|████████  | 80/100 [44:11<07:52, 23.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:40:58,825] Trial 79 finished with value: 0.22707126357338644 and parameters: {'use_batch_norm': True, 'learning_rate': 0.003718874777396663, 'weight_decay': 1.831912332558772e-05, 'batch_size': 128, 'hidden_size_0': 160, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.46507377190446886, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.11696754281703839}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  81%|████████  | 81/100 [44:40<08:01, 25.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:41:28,285] Trial 80 finished with value: 0.2380302821674317 and parameters: {'use_batch_norm': True, 'learning_rate': 0.00010008109244059926, 'weight_decay': 1e-06, 'batch_size': 112, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.5705609941642509, 'dropout_rate_1': 0.427721757568887, 'dropout_rate_2': 0.26255991345150054}. Best is trial 59 with value: 0.21596265567881187.\n",
      "Trial 80/100 | Best value: 0.2160 | Best trial: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  82%|████████▏ | 82/100 [44:53<06:26, 21.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:41:40,618] Trial 81 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 0.004951220171981026, 'weight_decay': 1e-06, 'batch_size': 80, 'hidden_size_0': 160, 'hidden_size_1': 48, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.5042677291733944, 'dropout_rate_2': 0.2997594086935208}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  83%|████████▎ | 83/100 [45:24<06:57, 24.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:42:12,415] Trial 82 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 1.680219148123632e-05, 'weight_decay': 1.6834320663963459e-06, 'batch_size': 96, 'hidden_size_0': 96, 'hidden_size_1': 80, 'hidden_size_2': 16, 'dropout_rate_0': 0.43361952294568207, 'dropout_rate_1': 0.5459914733331073, 'dropout_rate_2': 0.15062512515991233}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  84%|████████▍ | 84/100 [45:38<05:42, 21.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:42:26,454] Trial 83 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 0.0027939800364589393, 'weight_decay': 1e-06, 'batch_size': 96, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.24801537239460952}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  85%|████████▌ | 85/100 [46:13<06:18, 25.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:43:00,675] Trial 84 finished with value: 0.2290798789094608 and parameters: {'use_batch_norm': True, 'learning_rate': 0.0001840352497782189, 'weight_decay': 1e-06, 'batch_size': 96, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.5196669367907749, 'dropout_rate_2': 0.12349397942750936}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  86%|████████▌ | 86/100 [46:45<06:23, 27.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:43:33,071] Trial 85 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 2.0758683851380766e-05, 'weight_decay': 1e-06, 'batch_size': 96, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.4459277747398521, 'dropout_rate_2': 0.17739160934375162}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  87%|████████▋ | 87/100 [46:57<04:54, 22.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:43:44,608] Trial 86 finished with value: 0.22438722428483276 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0018453993848898474, 'weight_decay': 3.3198324305227494e-06, 'batch_size': 80, 'hidden_size_0': 96, 'hidden_size_1': 64, 'hidden_size_2': 64, 'dropout_rate_0': 0.31841799142816907, 'dropout_rate_1': 0.39999534482665927, 'dropout_rate_2': 0.17282223768633512}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  88%|████████▊ | 88/100 [47:09<03:53, 19.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:43:56,601] Trial 87 finished with value: 0.22579929867881965 and parameters: {'use_batch_norm': True, 'learning_rate': 0.002209647477451001, 'weight_decay': 0.004441769013342064, 'batch_size': 112, 'hidden_size_0': 96, 'hidden_size_1': 96, 'hidden_size_2': 32, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.526961605381357, 'dropout_rate_2': 0.14471916770389054}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  89%|████████▉ | 89/100 [47:27<03:30, 19.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:44:14,998] Trial 88 finished with value: 0.22366157701957187 and parameters: {'use_batch_norm': True, 'learning_rate': 0.004146425446800488, 'weight_decay': 0.001473375485637579, 'batch_size': 96, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.20601266100964596}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  90%|█████████ | 90/100 [48:03<04:00, 24.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:44:50,597] Trial 89 finished with value: 0.22732546864819003 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0002656130841676018, 'weight_decay': 5.171472423526908e-06, 'batch_size': 128, 'hidden_size_0': 96, 'hidden_size_1': 64, 'hidden_size_2': 64, 'dropout_rate_0': 0.48576258288608737, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.11475931294707978}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  91%|█████████ | 91/100 [48:38<04:07, 27.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:45:26,030] Trial 90 finished with value: 0.2278176308332192 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00025812221947330873, 'weight_decay': 4.264014914671574e-05, 'batch_size': 112, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.39397722965295423, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.21173932614363924}. Best is trial 59 with value: 0.21596265567881187.\n",
      "Trial 90/100 | Best value: 0.2160 | Best trial: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  92%|█████████▏| 92/100 [49:12<03:56, 29.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:46:00,489] Trial 91 finished with value: 0.22360739298748747 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0003776128815241347, 'weight_decay': 3.7582841436483065e-05, 'batch_size': 128, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.4381135329957988, 'dropout_rate_2': 0.18734219689775328}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  93%|█████████▎| 93/100 [50:13<04:31, 38.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:47:00,606] Trial 92 finished with value: 0.2510967519496302 and parameters: {'use_batch_norm': True, 'learning_rate': 5.732066511260845e-05, 'weight_decay': 1e-06, 'batch_size': 80, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.45741604867462915, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.21295341026720088}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  94%|█████████▍| 94/100 [50:28<03:10, 31.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:47:15,981] Trial 93 finished with value: 0.22611309924282624 and parameters: {'use_batch_norm': True, 'learning_rate': 0.002956225518664316, 'weight_decay': 1e-06, 'batch_size': 128, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.1}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  95%|█████████▌| 95/100 [51:08<02:51, 34.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:47:56,332] Trial 94 finished with value: inf and parameters: {'use_batch_norm': True, 'learning_rate': 3.2190918406264824e-05, 'weight_decay': 1e-06, 'batch_size': 128, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.20528957658653588, 'dropout_rate_2': 0.17609912430200347}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  96%|█████████▌| 96/100 [52:04<02:42, 40.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:48:51,948] Trial 95 finished with value: inf and parameters: {'use_batch_norm': False, 'learning_rate': 1.6210762887410642e-05, 'weight_decay': 0.00025946634894238375, 'batch_size': 64, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.3788178747860679, 'dropout_rate_1': 0.5861731431466575, 'dropout_rate_2': 0.12122043377603747}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  97%|█████████▋| 97/100 [52:33<01:52, 37.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:49:21,449] Trial 96 finished with value: 0.23204417778967315 and parameters: {'use_batch_norm': False, 'learning_rate': 0.0007661565597471408, 'weight_decay': 0.003732784462487344, 'batch_size': 112, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.5211205473066574, 'dropout_rate_2': 0.24959844088665462}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  98%|█████████▊| 98/100 [53:08<01:13, 36.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:49:56,201] Trial 97 finished with value: 0.22741331837394022 and parameters: {'use_batch_norm': False, 'learning_rate': 0.00070480486917522, 'weight_decay': 1e-06, 'batch_size': 80, 'hidden_size_0': 160, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.5451805905717804, 'dropout_rate_1': 0.6, 'dropout_rate_2': 0.13252338786897827}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963:  99%|█████████▉| 99/100 [53:29<00:31, 31.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:50:16,647] Trial 98 finished with value: 0.22047626023942773 and parameters: {'use_batch_norm': True, 'learning_rate': 0.003660003292622836, 'weight_decay': 1e-06, 'batch_size': 112, 'hidden_size_0': 32, 'hidden_size_1': 32, 'hidden_size_2': 32, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.5670809637756279, 'dropout_rate_2': 0.14925608122108253}. Best is trial 59 with value: 0.21596265567881187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 59. Best value: 0.215963: 100%|██████████| 100/100 [53:51<00:00, 32.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-13 21:50:38,560] Trial 99 finished with value: 0.2208151582359894 and parameters: {'use_batch_norm': True, 'learning_rate': 0.003291593520634592, 'weight_decay': 1e-06, 'batch_size': 96, 'hidden_size_0': 32, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.6, 'dropout_rate_1': 0.46605451817539856, 'dropout_rate_2': 0.23749106866426367}. Best is trial 59 with value: 0.21596265567881187.\n",
      "\n",
      "================================================================================\n",
      "PSO Optimization Complete!\n",
      "Best validation loss: 0.2160\n",
      "Best trial: 59\n",
      "\n",
      "Best Hyperparameters:\n",
      "  Architecture: 3 layers with ReLU activation\n",
      "  Layer 1: 32 neurons, dropout=0.600\n",
      "  Layer 2: 16 neurons, dropout=0.509\n",
      "  Layer 3: 16 neurons, dropout=0.129\n",
      "  Learning rate: 0.004355\n",
      "  Weight decay: 0.000001\n",
      "  Batch size: 96\n",
      "  Batch normalization: True\n",
      "\n",
      "Training final model with best hyperparameters...\n",
      "Starting training for 300 epochs with patience=50\n",
      "====================================================================================================\n",
      "Epoch   1/300 | Train: Loss 0.6159 Acc 65.89% F1 0.5265 AUROC 0.7072 | Val: Loss 0.4514 Acc 85.11% F1 0.8342 AUROC 0.9131\n",
      "Epoch  10/300 | Train: Loss 0.3355 Acc 88.87% F1 0.8630 AUROC 0.9154 | Val: Loss 0.2446 Acc 92.63% F1 0.9091 AUROC 0.9485\n",
      "Epoch  20/300 | Train: Loss 0.3143 Acc 90.14% F1 0.8792 AUROC 0.9168 | Val: Loss 0.2432 Acc 93.26% F1 0.9168 AUROC 0.9499\n",
      "Epoch  30/300 | Train: Loss 0.3174 Acc 90.03% F1 0.8778 AUROC 0.9179 | Val: Loss 0.2378 Acc 93.57% F1 0.9213 AUROC 0.9521\n",
      "Epoch  40/300 | Train: Loss 0.3078 Acc 90.45% F1 0.8832 AUROC 0.9209 | Val: Loss 0.2356 Acc 93.73% F1 0.9219 AUROC 0.9524\n",
      "Epoch  50/300 | Train: Loss 0.3121 Acc 90.03% F1 0.8776 AUROC 0.9171 | Val: Loss 0.2312 Acc 93.73% F1 0.9216 AUROC 0.9490\n",
      "Epoch  60/300 | Train: Loss 0.3080 Acc 90.48% F1 0.8826 AUROC 0.9211 | Val: Loss 0.2299 Acc 93.10% F1 0.9154 AUROC 0.9486\n",
      "Epoch  70/300 | Train: Loss 0.3034 Acc 90.70% F1 0.8852 AUROC 0.9189 | Val: Loss 0.2310 Acc 93.89% F1 0.9240 AUROC 0.9478\n",
      "Epoch  80/300 | Train: Loss 0.3063 Acc 90.14% F1 0.8794 AUROC 0.9208 | Val: Loss 0.2313 Acc 93.73% F1 0.9216 AUROC 0.9479\n",
      "Epoch  90/300 | Train: Loss 0.2994 Acc 90.39% F1 0.8819 AUROC 0.9234 | Val: Loss 0.2249 Acc 93.57% F1 0.9210 AUROC 0.9508\n",
      "Epoch 100/300 | Train: Loss 0.3023 Acc 90.56% F1 0.8835 AUROC 0.9229 | Val: Loss 0.2374 Acc 93.26% F1 0.9155 AUROC 0.9509\n",
      "Epoch 110/300 | Train: Loss 0.3072 Acc 90.56% F1 0.8837 AUROC 0.9175 | Val: Loss 0.2353 Acc 93.10% F1 0.9144 AUROC 0.9466\n",
      "Epoch 120/300 | Train: Loss 0.2996 Acc 90.56% F1 0.8833 AUROC 0.9257 | Val: Loss 0.2260 Acc 93.42% F1 0.9192 AUROC 0.9493\n",
      "Epoch 130/300 | Train: Loss 0.3023 Acc 90.42% F1 0.8820 AUROC 0.9201 | Val: Loss 0.2397 Acc 92.32% F1 0.9041 AUROC 0.9479\n",
      "Epoch 140/300 | Train: Loss 0.3061 Acc 90.37% F1 0.8813 AUROC 0.9215 | Val: Loss 0.2351 Acc 92.48% F1 0.9059 AUROC 0.9485\n",
      "====================================================================================================\n",
      "Early stopping at epoch 143\n",
      "====================================================================================================\n",
      "Training completed. Best model from epoch 93\n",
      "Best validation loss: 0.2218\n",
      "\n",
      "Final Model Performance:\n",
      "  Training Loss: 0.3054\n",
      "  Training Acc: 90.3101\n",
      "  Validation Loss: 0.2218\n",
      "  Validation Acc: 93.8871\n"
     ]
    }
   ],
   "source": [
    "from pso_hyperparameter_tuning import run_pso_hyperparameter_tuning\n",
    "\n",
    "# Your data (11 features, already scaled)\n",
    "pso_results = run_pso_hyperparameter_tuning(\n",
    "    X_train_scaled=X_train,  # Shape: (n_samples, 11)\n",
    "    y_train=y_train,\n",
    "    X_val_scaled=X_val,\n",
    "    y_val=y_val,\n",
    "    device=device,\n",
    "    n_trials=100,\n",
    "    n_particles=25,\n",
    "    epochs_per_trial=300,\n",
    "    patience=75,\n",
    "    inertia=0.8,\n",
    "    cognitive=1.4,\n",
    "    social=1.7,\n",
    "    verbose=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Get optimized model\n",
    "best_model = pso_results['final_model']\n",
    "best_params = pso_results['best_params']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b81ea7",
   "metadata": {},
   "source": [
    "[I 2025-10-13 21:29:19,328] Trial 50 finished with value: 0.23401889564662143 and parameters: \n",
    "`{'use_batch_norm': False, 'learning_rate': 0.0005995071316732543, 'weight_decay': 0.004937699977007833, 'batch_size': 96, 'hidden_size_0': 64, 'hidden_size_1': 16, 'hidden_size_2': 16, 'dropout_rate_0': 0.48246507786460235, 'dropout_rate_1': 0.5361848711639932, 'dropout_rate_2': 0.15099363078453903}`\n",
    "\n",
    "Best is trial 34 with value: 0.22146023387165278.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed307ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"pso_results_2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pso_results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-si",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
